package settings

import "net/url"

// KafkaSettings configures Kafka messaging for inter-service communication.
type KafkaSettings struct {
	Blocks                string   `key:"KAFKA_BLOCKS" desc:"Kafka topic name for blocks" default:"blocks" category:"Kafka" usage:"Topic for block distribution" type:"string" longdesc:"### Purpose\nPrimary channel for distributing newly discovered blocks across the network.\n\n### How It Works\n- P2P service publishes blocks received from peers\n- Block Validation service consumes messages for validation\n- Messages contain block hash, source URL, and peer ID\n\n### Recommendations\n- Use 1-2 partitions for sequential processing\n- Message rate is low (blocks every ~10 minutes)\n- Message size is small (~100 bytes)\n\n**Critical for block propagation.**"`
	BlocksFinal           string   `key:"KAFKA_BLOCKS_FINAL" desc:"Kafka topic name for finalized blocks" default:"blocks-final" category:"Kafka" usage:"Topic for finalized block notifications" type:"string" longdesc:"### Purpose\nNotifies services when a block has been fully validated and finalized, indicating it is ready for mining.\n\n### How It Works\n- Blockchain service publishes after successful validation\n- Block Assembly and other services consume to update state\n- Data flow: blocks topic -> validation -> blocks-final (success) or invalid-blocks (failure)\n\n### Recommendations\n- Use 1 partition (order is critical)\n- Message rate is low but latency-sensitive for mining efficiency\n\n**Critical for mining operations.**"`
	BlocksValidate        string   // Internal field, not directly configured
	Hosts                 string   `key:"KAFKA_HOSTS" desc:"Kafka broker addresses" default:"localhost:9092" category:"Kafka" usage:"Comma-separated list of broker addresses" type:"string" longdesc:"### Purpose\nSpecifies the Kafka broker addresses for client connections.\n\n### Format\nhost1:port1,host2:port2,host3:port3\n\n### How It Works\n- All Kafka consumers and producers across all services use this configuration\n- Clients connect to listed brokers for metadata discovery and message operations\n\n### Recommendations\n- Use DNS names (not IPs) for cloud deployments\n- List all brokers for failover and load balancing\n- Use **localhost:9092** for development only\n- Use **kafka1:9092,kafka2:9092,kafka3:9092** for multi-broker clusters\n\n**Critical configuration** - all Kafka operations depend on broker connectivity."`
	InvalidBlocks         string   `key:"KAFKA_INVALID_BLOCKS" desc:"Kafka topic for invalid blocks" default:"invalid-blocks" category:"Kafka" usage:"Topic for rejected block notifications" type:"string" longdesc:"### Purpose\nAlerts the network about blocks that failed validation for peer reputation management.\n\n### How It Works\n- Block Validation service publishes when validation fails\n- P2P service consumes to update peer reputation and ban malicious peers\n- Messages contain block hash, peer URL, and failure reason\n- Future blocks from flagged peers are deprioritized\n\n### Recommendations\n- Use 1 partition (low volume)\n- Use short retention (5 minutes)\n- Message rate is low normally but may spike during attacks\n\n**Critical for network security and DoS prevention.**"`
	InvalidSubtrees       string   `key:"KAFKA_INVALID_SUBTREES" desc:"Kafka topic for invalid subtrees" default:"invalid-subtrees" category:"Kafka" usage:"Topic for rejected subtree notifications" type:"string" longdesc:"### Purpose\nReports subtrees that failed validation for peer quality tracking.\n\n### How It Works\n- Subtree Validation service publishes when subtree contains invalid transactions\n- P2P service consumes to track subtree quality per peer\n- Messages contain subtree hash, peer URL, and validation failure reason\n- Includes 1-minute de-duplication cache to prevent flooding\n\n### Recommendations\n- Use 1 partition (very low volume)\n- Use short retention\n- Message rate may spike during malicious activity"`
	LegacyInv             string   `key:"KAFKA_LEGACY_INV" desc:"Kafka topic for legacy inventory messages" default:"legacy-inv" category:"Kafka" usage:"Topic for legacy peer inventory" type:"string" longdesc:"### Purpose\nBridges legacy Bitcoin wire protocol inventory messages to Kafka for hybrid network compatibility.\n\n### How It Works\n- Legacy Sync Manager acts as both producer and consumer (bidirectional)\n- Converts Bitcoin inv messages to Kafka format\n- Messages contain peer address and inventory vectors (MSG_TX, MSG_BLOCK types)\n\n### Recommendations\n- Use 2 partitions (medium volume)\n- Use moderate retention (10-30 minutes)\n- Message rate varies with legacy peer activity\n\nEnables compatibility with pre-libp2p Bitcoin nodes during network transitions."`
	Partitions            int      `key:"KAFKA_PARTITIONS" desc:"Number of Kafka topic partitions" default:"1" category:"Kafka" usage:"Higher values enable more parallelism" type:"int" longdesc:"### Purpose\nDefault number of partitions for Kafka topics, controlling parallelism and throughput.\n\n### How It Works\n- 1 partition enables sequential processing (simple but slower)\n- Multiple partitions enable parallel processing (better throughput)\n- More partitions allow more parallel consumers and horizontal scaling\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| More partitions | Higher parallelism, better throughput | Increased broker overhead |\n| Fewer partitions | Lower overhead, simpler | Limited parallelism |\n\n### Recommendations\n| Topic | Partitions |\n|-------|------------|\n| txmeta | 8+ |\n| subtrees | 4+ |\n| blocks | 1-2 |\n| blocks-final | 1 |\n| rejectedtx | 2-4 |\n| invalid-blocks/subtrees | 1 |\n| legacy-inv | 2 |\n\n**Critical scaling mechanism** for high-throughput scenarios."`
	Port                  int      `key:"KAFKA_PORT" desc:"Kafka broker port" default:"9092" category:"Kafka" usage:"Standard Kafka port" type:"int" longdesc:"### Purpose\nDefault Kafka broker port used when constructing broker URLs.\n\n### How It Works\n- Used as fallback when broker addresses do not include port numbers\n- Can be overridden in KAFKA_HOSTS by specifying explicit port per broker\n\n### Values\n| Port | Protocol |\n|------|----------|\n| 9092 | Plaintext |\n| 9093 | TLS |\n| 9094 | SASL |\n\n### Recommendations\n- **9092** (default) - Standard for non-TLS connections\n- **9093** - Use when TLS is enabled"`
	RejectedTx            string   `key:"KAFKA_REJECTEDTX" desc:"Kafka topic for rejected transactions" default:"rejectedtx" category:"Kafka" usage:"Topic for transaction rejections" type:"string" longdesc:"### Purpose\nBroadcasts transactions that failed validation for network-wide propagation control.\n\n### How It Works\n- Validator service publishes when validation fails during RUNNING state\n- P2P service consumes to prevent re-propagation and update peer reputation\n- Messages contain transaction hash, failure reason, and peer ID\n- P2P adds rejected transactions to filter so future announcements are ignored\n\n### Values\nCommon rejection reasons:\n- Invalid signature\n- Missing parent\n- Double-spend\n- Policy violation\n- Insufficient fee\n\n### Recommendations\n- Use 2-4 partitions for high volume\n- Use short retention (5-10 minutes)\n- Message rate can be high during spam attacks"`
	ReplicationFactor     int      `key:"KAFKA_REPLICATION_FACTOR" desc:"Kafka topic replication factor" default:"1" category:"Kafka" usage:"Increase for production fault tolerance" type:"int" longdesc:"### Purpose\nNumber of replica copies for each partition, providing fault tolerance and high availability.\n\n### How It Works\n- Data is replicated across multiple brokers\n- Must have at least replication_factor brokers in cluster\n- Higher values survive more broker failures\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher (3+) | Survives broker failures | More storage and network overhead |\n| Lower (1) | Lower overhead | Data loss if broker fails |\n\n### Values\n| Factor | Fault Tolerance |\n|--------|-----------------|\n| 1 | None (data loss if broker fails) |\n| 3 | Survives loss of 1 broker (production recommended) |\n| 5 | Survives loss of 2 brokers |\n\n### Recommendations\n| Topic Criticality | Factor |\n|-------------------|--------|\n| Critical (blocks, blocks-final, txmeta, subtrees) | 3 |\n| Less critical | 2 |\n\n### Warning\n**Critical topics should never use factor of 1 in production.**"`
	Subtrees              string   `key:"KAFKA_SUBTREES" desc:"Kafka topic for subtrees" default:"subtrees" category:"Kafka" usage:"Topic for subtree distribution" type:"string" longdesc:"### Purpose\nAnnounces availability of merkle subtrees for distributed validation.\n\n### How It Works\n- P2P service publishes when subtree received from network\n- Subtree Validation service consumes, fetches data, validates all transactions, and stores results\n- Messages contain subtree merkle root hash, base URL, block height, and block hash\n- Blocks contain multiple subtrees, enabling parallel transaction validation\n\n### Recommendations\n- Use 4-8 partitions (match validation worker count)\n- Use moderate retention (30-60 minutes)\n- Message rate is high (multiple subtrees per block)\n\n**Performance bottleneck** - partition count directly impacts validation throughput."`
	TxMeta                string   `key:"KAFKA_TXMETA" desc:"Kafka topic for transaction metadata" default:"txmeta" category:"Kafka" usage:"Topic for transaction metadata events" type:"string" longdesc:"### Purpose\nDistributes transaction metadata for caching and validation coordination.\n\n### How It Works\n- Validator service publishes after successful validation\n- Subtree Validation service consumes to update metadata cache\n- Cache is used for validating child transactions\n- Supports single messages (32-byte hash + metadata) or batched messages when TxMetaKafkaBatchSize > 0\n\n### Recommendations\n- Use 8-16 partitions (highest of all topics due to volume)\n- Use moderate retention (1-2 hours)\n- Message rate is very high (matches transaction validation rate)\n- Message size is variable (100-2000 bytes per tx)\n\n**Critical for validation performance** - cache misses slow validation."`
	UnitTest              string   `key:"KAFKA_UNITTEST" desc:"Kafka topic for unit tests" default:"unittest" category:"Kafka" usage:"Used in testing environment" type:"string" longdesc:"### Purpose\nDedicated topic for unit testing Kafka functionality.\n\n### How It Works\nUsed exclusively in testing environment to validate Kafka producer/consumer implementations without affecting production topics. Supports testing of message publishing, consumption, serialization, and error handling.\n\n**Not used in production deployments.**"`
	ValidatorTxsConfig    *url.URL `key:"kafka_validatortxsConfig" desc:"Kafka configuration URL for validator transactions" default:"" category:"Kafka" usage:"Advanced Kafka producer configuration" type:"url" longdesc:"### Purpose\nAdvanced configuration URL for validator transaction topic, overriding default settings.\n\n### Format\nkafka://broker1:9092,broker2:9092/topic-name?partitions=4&replication=3&retention=3600000\n\n### How It Works\nWhen specified, overrides default Kafka settings for this specific topic.\n\n### Values\n| Parameter | Description |\n|-----------|-------------|\n| partitions | Partition count override |\n| replication | Replication factor override |\n| retention | Message retention in ms |\n| segment_bytes | Log segment size |\n| flush_bytes | Producer flush size |\n\n**Note:** Currently unused in codebase."`
	TxMetaConfig          *url.URL `key:"kafka_txmetaConfig" desc:"Kafka configuration URL for transaction metadata" default:"" category:"Kafka" usage:"Advanced Kafka producer configuration" type:"url" longdesc:"### Purpose\nAdvanced configuration URL for transaction metadata topic, overriding default settings.\n\n### Format\nkafka://broker1:9092/txmeta?partitions=16&replication=3&retention=7200000\n\n### How It Works\nUsed by Validator service to create async Kafka producer for txmeta messages.\n\n### Recommendations\n| Parameter | Recommendation |\n|-----------|----------------|\n| partitions | High (8-16+) |\n| replication | 3 for production |\n| retention | 1-2 hours (for delayed consumers) |\n| segment_bytes | 1GB default |\n\n**Critical** for high-throughput transaction metadata distribution - should be tuned for highest message volume of all topics."`
	LegacyInvConfig       *url.URL `key:"kafka_legacyInvConfig" desc:"Kafka configuration URL for legacy inventory" default:"" category:"Kafka" usage:"Advanced Kafka producer configuration" type:"url" longdesc:"### Purpose\nAdvanced configuration URL for legacy inventory messages topic, supporting legacy Bitcoin protocol compatibility.\n\n### Format\nkafka://broker/legacy-inv?partitions=2&replication=2\n\n### How It Works\nUsed by Legacy Sync Manager for converting Bitcoin wire protocol inv messages to Kafka.\n\n### Recommendations\n| Parameter | Recommendation |\n|-----------|----------------|\n| partitions | 2 (medium volume) |\n| retention | 10-30 minutes (based on processing latency) |\n\nEnables hybrid network operation during transition from legacy to libp2p-based architecture."`
	BlocksFinalConfig     *url.URL `key:"kafka_blocksFinalConfig" desc:"Kafka configuration URL for finalized blocks" default:"" category:"Kafka" usage:"Advanced Kafka producer configuration" type:"url" longdesc:"### Purpose\nAdvanced configuration URL for finalized block notifications topic.\n\n### Format\nkafka://broker/blocks-final?partitions=1&replication=3\n\n### How It Works\nUsed by Blockchain service after successful block validation.\n\n### Recommendations\n| Parameter | Recommendation | Reason |\n|-----------|----------------|--------|\n| partitions | 1 | Order critical for finalization sequence |\n| replication | 3 minimum | High availability critical for mining |\n| retention | 10-30 minutes | |\n\n### Warning\n**Replication factor should never be 1 in production** - critical for mining operations requiring high availability and low latency."`
	RejectedTxConfig      *url.URL `key:"kafka_rejectedTxConfig" desc:"Kafka configuration URL for rejected transactions" default:"" category:"Kafka" usage:"Advanced Kafka producer configuration" type:"url" longdesc:"### Purpose\nAdvanced configuration URL for rejected transaction notifications.\n\n### Format\nkafka://broker/rejectedtx?partitions=4&replication=2&retention=300000\n\n### How It Works\n- Validator service publishes validation failures\n- P2P service consumes for propagation control\n\n### Recommendations\n| Parameter | Recommendation | Reason |\n|-----------|----------------|--------|\n| partitions | 2-4 | For high volume spam scenarios |\n| replication | 2 | Adequate for this topic |\n| retention | 5-10 minutes | Only needs to prevent re-propagation |\n\nMessage rate can be high during attacks - tune partitions accordingly."`
	InvalidBlocksConfig   *url.URL `key:"kafka_invalidBlocksConfig" desc:"Kafka configuration URL for invalid blocks" default:"" category:"Kafka" usage:"Advanced Kafka producer configuration" type:"url" longdesc:"### Purpose\nAdvanced configuration URL for invalid block notifications, critical for network security.\n\n### Format\nkafka://broker/invalid-blocks?partitions=1&replication=3&retention=300000\n\n### How It Works\n- Block Validation service publishes validation failures\n- P2P service consumes for peer banning\n- Enables P2P circuit breakers and peer reputation management\n\n### Recommendations\n| Parameter | Recommendation | Reason |\n|-----------|----------------|--------|\n| partitions | 1 | Low volume |\n| replication | 2-3 | Important for security |\n| retention | 5 minutes | Consumed quickly for peer banning |\n\n### Warning\n**Must not be disabled in production** - critical for DoS prevention."`
	InvalidSubtreesConfig *url.URL `key:"kafka_invalidSubtreesConfig" desc:"Kafka configuration URL for invalid subtrees" default:"" category:"Kafka" usage:"Advanced Kafka producer configuration" type:"url" longdesc:"### Purpose\nAdvanced configuration URL for invalid subtree notifications topic. Helps identify peers sending bad subtree data for quality tracking.\n\n### Format\nkafka://broker/invalid-subtrees?partitions=1&replication=2&retention=300000\n\n### How It Works\nUsed by Subtree Validation service with built-in 1-minute de-duplication to prevent flooding.\n\n### Recommendations\n| Parameter | Recommendation | Reason |\n|-----------|----------------|--------|\n| partitions | 1 | Very low volume |\n| replication | 2 | Adequate |\n| retention | 5 minutes | Short |\n\nMessage rate very low under normal conditions, may spike during malicious activity."`
	SubtreesConfig        *url.URL `key:"kafka_subtreesConfig" desc:"Kafka configuration URL for subtrees" default:"" category:"Kafka" usage:"Advanced Kafka producer configuration" type:"url" longdesc:"### Purpose\nAdvanced configuration URL for subtree distribution topic, critical for block validation performance.\n\n### Format\nkafka://broker/subtrees?partitions=8&replication=3&retention=3600000\n\n### How It Works\n- P2P service produces subtree announcements\n- Subtree Validation service consumes for validation\n- High message rate (multiple subtrees per block) enables parallel transaction validation\n\n### Recommendations\n| Parameter | Recommendation | Reason |\n|-----------|----------------|--------|\n| partitions | 4-8 | Should match validation worker count |\n| replication | 3 | Production standard |\n| retention | 30-60 minutes | |\n\n**Performance bottleneck** - partition count directly impacts validation throughput."`
	BlocksConfig          *url.URL `key:"kafka_blocksConfig" desc:"Kafka configuration URL for blocks" default:"" category:"Kafka" usage:"Advanced Kafka producer configuration" type:"url" longdesc:"### Purpose\nAdvanced configuration URL for block distribution topic.\n\n### Format\nkafka://broker/blocks?partitions=2&replication=3&retention=600000\n\n### How It Works\n- P2P service produces block announcements\n- Block Validation service consumes for validation\n- Message rate is low (blocks every ~10 minutes) with small message size (~100 bytes metadata)\n\n### Recommendations\n| Parameter | Recommendation | Reason |\n|-----------|----------------|--------|\n| partitions | 1-2 | Order somewhat important |\n| replication | 3 | High availability for production |\n| retention | 10 minutes | Default |\n\n**Critical for block propagation** - must be highly available."`
	// TLS settings
	EnableTLS     bool   `key:"KAFKA_ENABLE_TLS" desc:"Enable TLS for Kafka connections" default:"false" category:"Kafka" usage:"Enable for secure broker communication" type:"bool" longdesc:"### Purpose\nEnable TLS encryption for all Kafka connections, securing data in transit.\n\n### How It Works\nWhen enabled, configures Sarama client with TLS transport using:\n- TLSCAFile for CA certificate verification\n- TLSCertFile for client certificate (mutual TLS)\n- TLSKeyFile for client private key (mutual TLS)\n\n### Recommendations\n- Required for production deployments\n- Required for multi-tenant environments\n- Required for compliance (PCI, HIPAA)\n- Required for cross-datacenter communication\n- Brokers must also have TLS enabled\n- Ports typically change: 9092 to 9093 for TLS\n- Performance overhead is minimal (<5%) with modern CPUs\n\n### Warning\n**Never disable in production environments.**"`
	TLSSkipVerify bool   `key:"KAFKA_TLS_SKIP_VERIFY" desc:"Skip TLS certificate verification" default:"false" category:"Kafka" usage:"Only for testing with self-signed certs" type:"bool" longdesc:"### Purpose\nSkip TLS certificate verification.\n\n### Warning\n**TESTING ONLY - NEVER USE IN PRODUCTION**\n\nWhen true, accepts any certificate presented by broker without verification, enabling man-in-the-middle attacks.\n\n### How It Works\nBypasses:\n- Certificate chain validation\n- Hostname verification\n- Expiration checks\n\n### Values\n- **false** (default) - Required for production, provide proper CA certificates via TLSCAFile\n- **true** - Only for local development with self-signed certificates\n\n**Keeping this true in production violates security best practices and compliance requirements.**"`
	TLSCAFile     string `key:"KAFKA_TLS_CA_FILE" desc:"Path to Kafka TLS CA certificate file" default:"" category:"Kafka" usage:"Required when EnableTLS is true" type:"string" longdesc:"### Purpose\nPath to Certificate Authority (CA) certificate file for TLS verification.\n\n### Format\nPEM-encoded X.509 CA certificate (e.g., /etc/kafka/ssl/ca-cert.pem)\n\n### How It Works\n- Loaded and added to tls.Config.RootCAs\n- Validates broker certificates are signed by trusted CA\n- Prevents connections to rogue brokers with untrusted certificates\n- Validated on startup - file must exist and contain valid PEM certificate\n\n### Recommendations\n- Required when EnableTLS=true\n- If not specified with EnableTLS=true, system CA pool is used (may not include Kafka CA)"`
	TLSCertFile   string `key:"KAFKA_TLS_CERT_FILE" desc:"Path to Kafka TLS client certificate file" default:"" category:"Kafka" usage:"For client certificate authentication" type:"string" longdesc:"### Purpose\nPath to client certificate file for mutual TLS (mTLS) authentication.\n\n### Format\nPEM-encoded X.509 client certificate (e.g., /etc/kafka/ssl/client-cert.pem)\n\n### How It Works\n- Loaded via tls.LoadX509KeyPair with TLSKeyFile\n- Added to tls.Config.Certificates\n- Enables mutual TLS where broker verifies client identity (more secure than server-only TLS)\n- Validated on startup to ensure certificate and key are valid pair\n\n### Recommendations\n- Required when broker requires client certificate authentication\n- **Must be provided together with TLSKeyFile** - both or neither"`
	TLSKeyFile    string `key:"KAFKA_TLS_KEY_FILE" desc:"Path to Kafka TLS client key file" default:"" category:"Kafka" usage:"For client certificate authentication" type:"string" longdesc:"### Purpose\nPath to client private key file for mutual TLS (mTLS) authentication.\n\n### Format\nPEM-encoded private key, RSA or ECDSA (e.g., /etc/kafka/ssl/client-key.pem)\n\n### How It Works\n- Loaded via tls.LoadX509KeyPair with TLSCertFile\n- Private key must correspond to public key in client certificate\n- Validated on startup to ensure key matches certificate\n\n### Recommendations\n- Required when broker requires client certificate authentication\n- **Must be provided together with TLSCertFile** - both or neither\n- File permissions should be restricted (0600) to protect private key"`
	// Debug logging
	EnableDebugLogging bool   `key:"kafka_enable_debug_logging" desc:"Enable debug logging for Kafka client" default:"false" category:"Kafka" usage:"Useful for troubleshooting connection issues" type:"bool" longdesc:"### Purpose\nEnable verbose debug logging for Kafka client operations.\n\n### How It Works\nWhen enabled, logs detailed information about:\n- Connection attempts and broker communication\n- Metadata requests\n- Produce/consume operations\n- Partition assignments and rebalancing\n- Consumer group coordination\n- Errors\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Enabled | Detailed troubleshooting info | High logging overhead, large log volume |\n| Disabled | Normal performance | Less visibility into client behavior |\n\n### Recommendations\n- Use for troubleshooting connection issues\n- Use for debugging message delivery problems\n- **Disable in production** due to performance impact"`
	Scheme             string `key:"KAFKA_SCHEMA" desc:"Kafka connection scheme" default:"http" category:"Kafka" usage:"Use 'kafka' for standard, 'memory' for testing" type:"string" longdesc:"### Purpose\nConnection scheme for Kafka client.\n\n### Values\n| Scheme | Description |\n|--------|-------------|\n| kafka | Standard Kafka broker connections |\n| memory | In-memory mock implementation (testing only) |\n\n### How It Works\n- **kafka** scheme connects to real brokers specified in KAFKA_HOSTS\n- **memory** scheme uses in-memory broker (imk.GetSharedBroker()) providing sarama.SyncProducer and sarama.Consumer interfaces without requiring a Kafka cluster\n\n### Recommendations\n- **Production**: Must use kafka\n- **CI/CD pipelines**: memory scheme useful for testing\n- **Local development**: memory scheme useful for unit tests"`
}
