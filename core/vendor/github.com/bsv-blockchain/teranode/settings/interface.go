package settings

import (
	"net/url"
	"time"

	"github.com/bsv-blockchain/go-chaincfg"
)

// listen mode constants
const (
	ListenModeFull       = "full"
	ListenModeListenOnly = "listen_only"
)

// Settings is the main configuration structure containing all Teranode settings.
// Individual settings categories are defined in separate files for organization.

// Pruner block trigger mode constants
const (
	PrunerBlockTriggerOnBlockPersisted = "OnBlockPersisted" // Trigger on BlockPersisted notifications (default)
	PrunerBlockTriggerOnBlockMined     = "OnBlockMined"     // Trigger on Block notifications with mined_set=true
)

type Settings struct {
	Commit                       string   // Runtime-computed from build info
	Version                      string   // Runtime-computed from build info
	Context                      string   // Runtime-computed from config context
	IsAllInOneMode               bool     // Runtime-computed: true if daemon is running multiple services in a single process
	ServiceName                  string   `key:"SERVICE_NAME" desc:"Service name identifier" default:"teranode" category:"Global" usage:"Used for logging and identification" type:"string" longdesc:"### Purpose\nIdentifies which Teranode service (blockchain, validator, p2p, etc.) generated each log entry or trace span.\n\n### How It Works\n- Embedded in OpenTelemetry traces via semconv.ServiceNameKey\n- Appears in all log messages\n- Used by util/tracing/otel.go during tracer initialization\n\n### Recommendations\n- Use descriptive names like **teranode-validator** or **teranode-blockchain** for easier debugging\n- Default value **teranode** is suitable for single-service deployments"`
	TracingEnabled               bool     `key:"tracing_enabled" desc:"Enable OpenTelemetry distributed tracing" default:"false" category:"Global" usage:"Enable for debugging request flows across services" type:"bool" longdesc:"### Purpose\nMaster switch for OpenTelemetry distributed tracing across all Teranode services.\n\n### How It Works\n- When enabled, initializes OTLP HTTP exporter in daemon/daemon_services.go and util/tracing/otel.go\n- Sends trace data to TracingCollectorURL (typically Jaeger)\n- Captures request flows across gRPC boundaries, Kafka message processing, and database operations\n- When disabled, all tracing operations become no-ops via atomic flag check for zero performance overhead\n\n### Recommendations\n- **true** - Enable for debugging microservice interactions and performance bottlenecks\n- **false** (default) - Disable when tracing infrastructure is not available"`
	TracingSampleRate            float64  `key:"tracing_SampleRate" desc:"Percentage of requests to trace (0.0 to 1.0)" default:"0.01" category:"Global" usage:"Lower values reduce overhead; 0.01 = 1% of requests" type:"float64" longdesc:"### Purpose\nControls what fraction of requests generate trace spans for distributed tracing.\n\n### How It Works\nImplemented via sdktrace.TraceIDRatioBased() in util/tracing/otel.go. Impact is minimal when disabled but increases linearly with sample rate.\n\n### Values\n- **0.0** - No tracing\n- **0.01** (default) - 1% of requests\n- **1.0** - Trace everything\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Lower (0.001-0.01) | Reduced overhead and storage costs | Fewer traces for debugging |\n| Higher (0.1-1.0) | Comprehensive debugging data | Increased collector load and storage |\n\n### Recommendations\n- **0.01** (default) - Good balance for production\n- Increase temporarily during active debugging sessions"`
	TracingCollectorURL          *url.URL `key:"tracing_collector_url" desc:"OpenTelemetry collector endpoint for trace data" default:"http://localhost:4318" category:"Global" usage:"Point to your OTLP-compatible collector" type:"url" longdesc:"### Purpose\nSpecifies the OTLP HTTP endpoint URL for sending OpenTelemetry trace data.\n\n### How It Works\n- Configured in util/tracing/otel.go via otlptracehttp.WithEndpoint()\n- Traces are batched and sent every second via sdktrace.WithBatchTimeout()\n- Connection errors during initialization are logged but do not prevent service startup\n- Invalid URLs cause tracer initialization to fail with \"failed to create OTLP exporter\" error\n\n### Format\n**http(s)://host:port** - OTLP-compatible collector endpoint.\n\n### Examples\n- **http://localhost:4318** - Local Jaeger collector (default)\n- **https://tempo.internal:4318** - Grafana Tempo\n- **https://api.honeycomb.io:443** - Honeycomb\n\n### Recommendations\n- Use your OTLP-compatible observability backend (Jaeger, Grafana Tempo, Honeycomb)\n- Default is suitable for local development only"`
	ClientName                   string   `key:"clientName" desc:"Client identifier for peer connections" default:"defaultClientName" category:"Global" usage:"Identifies this node to other peers" type:"string" longdesc:"### Purpose\nProvides a human-readable identifier for this Teranode instance in peer-to-peer communications.\n\n### How It Works\n- Used by services/p2p/Server.go to populate ClientName field in peer handshake messages\n- Visible in peer lists via Asset HTTP API /peers endpoint\n- Appears in P2P service responses\n\n### Examples\n- **miner-01** - Mining node identifier\n- **validator-west** - Regional validator\n- **archive-node-1** - Archive node\n\n### Recommendations\n- Use unique names per node for easier debugging\n- Default value **defaultClientName** is suitable for single-node testing only"`
	DataFolder                   string   `key:"dataFolder" desc:"Base directory for storing blockchain data files" default:"data" category:"Global" usage:"Ensure sufficient disk space and appropriate permissions" type:"string" longdesc:"### Purpose\nRoot directory for all persistent Teranode data storage, essential for state persistence across restarts.\n\n### How It Works\nEach service creates subdirectories within this folder:\n- data/blockchain/ - Blockchain state\n- data/utxo/ - UTXO data\n\nContents include SQLite databases, file-based blob stores, and checkpoint files.\n\n### Format\nAbsolute or relative path. Relative paths are resolved from the working directory.\n\n### Recommendations\n- Must have write permissions for the process user\n- For production, point to a dedicated volume with sufficient capacity for blockchain growth (TBs)\n- **data** (default) - Suitable for development only"`
	SecurityLevelHTTP            int      `key:"securityLevelHTTP" desc:"HTTP security level (0=HTTP, non-zero=HTTPS)" default:"0" category:"Global" usage:"Set to 1 or higher and provide certificates for HTTPS" type:"int" longdesc:"### Purpose\nControls HTTP transport security for Asset HTTP server and P2P WebSocket connections.\n\n### How It Works\nUsed by services/asset/httpimpl/http.go and services/p2p/Server.go to determine whether to call e.Server.Serve() (HTTP) or e.Server.ServeTLS() (HTTPS).\n\n### Values\n- **0** - Plain HTTP (insecure)\n- **1 or higher** - HTTPS with TLS encryption\n\n### Security\nWhen set to non-zero, both ServerCertFile and ServerKeyFile must be provided and valid, otherwise service startup fails with certificate errors.\n\n### Recommendations\n- **Production**: Always use HTTPS (non-zero) to encrypt sensitive blockchain data and API credentials in transit\n- **Development**: HTTP (0) is acceptable for local testing only"`
	ServerCertFile               string   `key:"server_certFile" desc:"Path to TLS certificate file for HTTPS" default:"" category:"Global" usage:"Required when securityLevelHTTP > 0" type:"string" longdesc:"### Purpose\nSpecifies the file path to PEM-encoded TLS certificate used for HTTPS connections.\n\n### How It Works\nReferenced by services/asset/httpimpl/http.go during Start() for HTTPS server initialization. Used in conjunction with ServerKeyFile to establish TLS sessions.\n\n### Format\nAbsolute or relative path to PEM-encoded certificate file.\n\n### Recommendations\n- Required when SecurityLevelHTTP is non-zero\n- File must be readable by the Teranode process\n- Certificate sources: Let's Encrypt (production), Internal PKI, or self-signed (testing only)\n\n### Warning\nStartup fails with \"server_certFile is required for HTTPS\" error if missing when HTTPS is enabled."`
	ServerKeyFile                string   `key:"server_keyFile" desc:"Path to TLS private key file for HTTPS" default:"" category:"Global" usage:"Required when securityLevelHTTP > 0" type:"string" longdesc:"### Purpose\nSpecifies the file path to PEM-encoded TLS private key corresponding to ServerCertFile.\n\n### How It Works\nUsed by services/asset/httpimpl/http.go during HTTPS server startup via e.Server.ServeTLS().\n\n### Format\nAbsolute or relative path to PEM-encoded private key file.\n\n### Security\n- Private key must remain confidential\n- File permissions should be restrictive (600 or 400)\n- Compromise of this key allows man-in-the-middle attacks on HTTPS connections\n- For production, store securely and rotate periodically\n\n### Warning\nStartup fails with \"server_keyFile is required for HTTPS\" error if missing when HTTPS is enabled."`
	Logger                       string   `key:"logger" desc:"Logger configuration string" default:"" category:"Global" usage:"Leave empty for default logging behavior" type:"string" longdesc:"### Purpose\nReserved logger configuration string for advanced logging setup.\n\n### How It Works\nWhen empty, logging is initialized via ulogger package with standard zerolog-based output to stdout/stderr. Default logging behavior is configured via LogLevel, PrettyLogs, and JSONLogging settings.\n\n### Recommendations\n- Leave empty to use default logging behavior\n- May support future logger-specific configurations like custom formatters, output destinations, and log routing rules"`
	LogLevel                     string   `key:"logLevel" desc:"Application log level (DEBUG, INFO, WARN, ERROR, FATAL)" default:"INFO" category:"Global" usage:"Lower levels generate more logs" type:"string" longdesc:"### Purpose\nControls global logging verbosity across all Teranode services.\n\n### How It Works\nConfigured via gocore.Config() and checked by ulogger throughout the codebase. Debug subsystem flags (debug_all, debug_file, etc.) require DEBUG level to emit output.\n\n### Values\n- **DEBUG** - Most verbose: detailed operation traces, database queries, cache hits/misses, gRPC calls\n- **INFO** (default) - Normal operations, transactions, blocks\n- **WARN** - Warnings and potential issues\n- **ERROR** - Error conditions\n- **FATAL** - Least verbose: critical failures only\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| DEBUG | Detailed traces for troubleshooting | High log volume, may impact performance |\n| INFO | Balanced operational visibility | Less detail for debugging |\n| WARN+ | Minimal log volume | May miss important context |\n\n### Recommendations\n- **Production**: Use INFO with selective DEBUG for troubleshooting\n- **Development**: DEBUG for detailed traces"`
	PrettyLogs                   bool     `key:"prettyLogs" desc:"Enable human-readable log formatting" default:"false" category:"Global" usage:"Useful for development; disable in production for structured logs" type:"bool" longdesc:"### Purpose\nEnables human-readable, color-coded log formatting for local development and debugging.\n\n### How It Works\n- When enabled, logs are formatted with colors, indentation, and readable timestamps via zerolog ConsoleWriter\n- When disabled, logs use compact machine-readable format without colors\n- Cannot be changed at runtime - requires service restart\n\n### Values\n- **true** - Human-readable formatting with colors\n- **false** (default) - Compact machine-readable format\n\n### Warning\nMutually exclusive with JSONLogging - enabling both results in undefined behavior.\n\n### Recommendations\n- **Development**: Enable for better readability\n- **Production**: Disable for consistent parsing by log aggregation tools (ELK, Splunk, Grafana Loki)"`
	JSONLogging                  bool     `key:"jsonLogging" desc:"Enable JSON-formatted log output" default:"false" category:"Global" usage:"Recommended for production log aggregation systems" type:"bool" longdesc:"### Purpose\nEnables structured JSON log output for production log aggregation and analysis systems.\n\n### How It Works\nEach log line is a JSON object with fields: level, msg, timestamp, service, and context-specific fields. Implemented in ulogger package via gocore.Config jsonLogging setting. Cannot be changed at runtime.\n\n### Values\n- **true** - JSON-formatted output for machine parsing\n- **false** (default) - Standard text output\n\n### Warning\nMutually exclusive with PrettyLogs - enabling both results in undefined behavior.\n\n### Recommendations\n- **Production**: Enable for log processing pipelines (Elasticsearch, Loki, Splunk, CloudWatch Logs)\n- **Development**: Disable for human readability"`
	Debug                        DebugSettings
	ProfilerAddr                 string `key:"profilerAddr" desc:"Address for pprof profiler server" default:"" category:"Global" usage:"Enable for runtime profiling (e.g., localhost:6060)" type:"string" longdesc:"### Purpose\nSpecifies the TCP address for Go pprof HTTP profiling server, essential for diagnosing performance issues, memory leaks, and goroutine deadlocks.\n\n### How It Works\nWhen set, starts an HTTP server exposing at /debug/pprof/: CPU profiles, memory profiles, goroutine dumps, and other runtime diagnostics. Used by daemon/daemon_services.go startProfilerAndMetrics().\n\n### Format\n**host:port** or **:port** for binding.\n\n### Examples\n- **localhost:6060** - Localhost only (recommended)\n- **:6060** - All interfaces\n- **empty** - Profiling disabled (default)\n\n### Security\nProfiler exposes internal process state - bind to localhost in production or use firewall rules to restrict access."`
	StatsPrefix                  string `key:"stats_prefix" desc:"Prefix for metrics names" default:"" category:"Global" usage:"Used to namespace metrics in monitoring systems" type:"string" longdesc:"### Purpose\nNamespace prefix for gocore stats metrics to avoid naming collisions when running multiple Teranode instances.\n\n### How It Works\nPrepended to all metric names exposed via gocore stats system (/stats endpoint). Used by cmd/seeder/seeder.go when registering stats handlers. Does not affect Prometheus metrics, which use different labeling.\n\n### Examples\n- **node1** - Metrics appear as node1.stat_name\n- **empty** (default) - No prefix, metrics appear as stat_name\n\n### Recommendations\n- Use in multi-instance deployments to distinguish metrics from different nodes\n- Leave empty for single-instance deployments"`
	PrometheusEndpoint           string `key:"prometheusEndpoint" desc:"Endpoint path for Prometheus metrics" default:"/metrics" category:"Global" usage:"Standard Prometheus scraping endpoint" type:"string" longdesc:"### Purpose\nHTTP endpoint path for Prometheus metrics scraping.\n\n### How It Works\nWhen ProfilerAddr is set, Prometheus handler exposes: gRPC call counts (if UsePrometheusGRPCMetrics enabled), database pool stats, Kafka producer/consumer metrics, and custom business metrics. Scraped periodically by Prometheus server for time-series monitoring and alerting.\n\n### Format\nHTTP path starting with /.\n\n### Values\n- **/metrics** (default) - Standard Prometheus convention\n- Custom paths if /metrics conflicts with application paths\n\n### Recommendations\n- Leave as default unless specific conflict exists\n- Non-standard values require Prometheus scrape_configs adjustment"`
	HealthCheckHTTPListenAddress string `key:"health_check_httpListenAddress" desc:"Health check HTTP listen address" default:"" category:"Global" usage:"Endpoint for health checks (e.g., :8080/health)" type:"string" longdesc:"### Purpose\nSpecifies the TCP listen address for dedicated health check HTTP endpoint, essential for container orchestration and load balancer health monitoring.\n\n### How It Works\nUsed by daemon/daemon.go to start a lightweight HTTP server via util.GetListener() that responds to health check requests (typically at /health). When empty, health checks may be disabled or served via main HTTP service.\n\n### Format\n- **:port** - Listen on all interfaces\n- **host:port** - Listen on specific interface\n- **empty** (default) - Health checks disabled or via main service\n\n### Recommendations\n- Essential for Kubernetes liveness/readiness probes and Docker healthchecks\n- Separate from main service ports to allow health checks during service degradation\n\n### Security\nShould be accessible from orchestration platform but not publicly exposed."`
	UseDatadogProfiler           bool   `key:"use_datadog_profiler" desc:"Enable Datadog profiler integration" default:"false" category:"Global" usage:"Requires Datadog agent and configuration" type:"bool" longdesc:"### Purpose\nEnables Datadog continuous profiler integration for production performance monitoring.\n\n### How It Works\nInitializes Datadog profiler in daemon/daemon_services.go via datadogProfiler() collecting: CPU profiles, heap allocations, goroutine counts, and mutex contention data. Minimal overhead (typically <1%).\n\n### Values\n- **true** - Enable Datadog profiling (requires Datadog agent)\n- **false** (default) - Profiling disabled\n\n### Requirements\nWhen enabled, requires Datadog agent running and proper DD_* environment variables: DD_SERVICE, DD_ENV, DD_VERSION, DD_AGENT_HOST.\n\n### Recommendations\n- **Production**: Enable for observability (complements Prometheus metrics with code-level insights)\n- **Development**: Leave disabled unless testing Datadog integration"`
	LocalTestStartFromState      string `key:"local_test_start_from_state" desc:"Load initial state from file for testing" default:"" category:"Global" usage:"Used for testing specific blockchain states" type:"string" longdesc:"### Purpose\nFile path to blockchain state snapshot for initializing test environments with specific blockchain heights and UTXO sets.\n\n### How It Works\nWhen set, blockchain service loads serialized state from this file during initialization. Enables testing of specific blockchain conditions without replaying entire chain history: deep reorgs, large UTXO sets, specific consensus scenarios.\n\n### Format\nAbsolute or relative path to serialized state file.\n\n### Values\n- **empty** (default) - Start from genesis\n- **path/to/state** - Load from snapshot file\n\n### Warning\nUsed exclusively in testing scenarios. Should always be empty in production deployments."`
	PostgresCheckAddress         string `key:"postgres_check_address" desc:"PostgreSQL health check address" default:"" category:"Postgres" usage:"Used for database connection validation" type:"string" longdesc:"### Purpose\nPostgreSQL server address used for database connectivity health checks during startup.\n\n### How It Works\nUsed by daemon/daemon.go waitForPostgresToStart() when -wait_for_postgres=1 command-line flag is provided. Service initialization blocks until successful connection, preventing startup failures when PostgreSQL starts slower than Teranode. Timeout and retry logic ensure graceful handling of temporary unavailability.\n\n### Format\n**host:port** (e.g., localhost:5432 or postgres.example.com:5432)\n\n### Recommendations\n- Essential for containerized deployments (Docker Compose, Kubernetes) where startup order is not guaranteed\n- Should match the actual PostgreSQL host used by Blockchain store and other services\n- Leave empty if not using wait_for_postgres flag"`
	Postgres                     PostgresSettings
	UseCgoVerifier               bool          `key:"use_cgo_verifier" desc:"Use CGO-based transaction verifier" default:"false" category:"Global" usage:"Faster verification but requires CGO" type:"bool" longdesc:"### Purpose\nEnables CGO-based Bitcoin transaction signature verification using optimized C libraries (libsecp256k1).\n\n### How It Works\n- When enabled, uses faster C implementation for ECDSA signature verification (typically 3-5x faster than pure Go)\n- When disabled, falls back to pure Go implementation (slower but eliminates CGO dependency)\n\n### Values\n- **true** - Use CGO-based verifier (faster, requires CGO)\n- **false** (default) - Use pure Go verifier (portable)\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Enabled | 3-5x faster verification | Requires CGO, complicates cross-compilation |\n| Disabled | Portable, deterministic builds | Slower verification |\n\n### Recommendations\n- **Production**: Enable for high-throughput nodes\n- **Development**: Disable if encountering CGO build/runtime issues"`
	GRPCResolver                 string        `key:"grpc_resolver" desc:"gRPC resolver scheme" default:"dns" category:"Global" usage:"Used for service discovery (dns, passthrough)" type:"string" longdesc:"### Purpose\nSpecifies the gRPC name resolution scheme for service discovery in distributed deployments.\n\n### How It Works\nUsed by util/grpc_helper.go GetGRPCClient() to resolve service addresses. Affects all gRPC client connections across all services. When empty, defaults to dns via resolver.SetDefaultScheme().\n\n### Values\n- **dns** (default) - Standard DNS resolution (supports SRV records for load balancing)\n- **passthrough** - Address used as-is without resolution\n- **kubernetes** - Integrates with k8s service discovery\n- Custom resolvers for service mesh integration (Consul, Etcd, etc.)\n\n### Recommendations\n- **dns** - Suitable for most deployments\n- **passthrough** - When using explicit IP addresses or service mesh proxies"`
	GRPCMaxRetries               int           `key:"grpc_max_retries" desc:"Maximum gRPC retry attempts" default:"3" category:"Global" usage:"Applies to all gRPC client calls" type:"int" longdesc:"### Purpose\nControls the maximum number of retry attempts for failed gRPC calls across all service-to-service communications.\n\n### How It Works\nApplied by util/grpc_helper.go GetGRPCClient() to all gRPC clients (blockchain, validator, propagation, p2p, blockvalidation, blockassembly). Retries on connection errors, timeouts, and unavailable status. No retries on invalid request, auth failure, or other application errors. Individual services may override with service-specific settings.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Increased resilience to transient failures | May delay error reporting |\n| Lower | Faster failure detection | Reduced tolerance for temporary issues |\n\n### Recommendations\n- **3** (default) - Good balance for most environments\n- Increase for unreliable networks\n- Decrease for faster failure detection"`
	GRPCRetryBackoff             time.Duration `key:"grpc_retry_backoff" desc:"gRPC retry backoff duration" default:"1s" category:"Global" usage:"Exponential backoff starting duration" type:"duration" longdesc:"### Purpose\nSets the initial backoff duration between gRPC retry attempts, used for exponential backoff calculation.\n\n### How It Works\nWhen a gRPC call fails with retryable error: client waits this duration before first retry, then duration doubles for subsequent retries (exponential backoff). Applied via util/grpc_helper.go to all gRPC clients. Works in conjunction with GRPCMaxRetries to define total retry window.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Lower | Faster recovery from transient failures | Risk overwhelming recovering services |\n| Higher | Reduced server load during issues | Increased perceived latency |\n\n### Recommendations\n- **1s** (default) - Good balance for most environments\n- Increase for services with longer recovery times"`
	SecurityLevelGRPC            int           `key:"security_level_grpc" desc:"gRPC security level (0=insecure, non-zero=TLS)" default:"0" category:"Global" usage:"Set to 1 or higher for TLS" type:"int" longdesc:"### Purpose\nControls TLS encryption for all inter-service gRPC communications.\n\n### How It Works\nImplemented in util/grpc_helper.go GetGRPCClient() which creates insecure.NewCredentials() for value 0 or credentials.NewTLS() for non-zero values. When non-zero, requires certificate configuration.\n\n### Values\n- **0** (default) - Insecure plaintext connections\n- **1 or higher** - TLS encryption for gRPC channels\n\n### Recommendations\n- **Production**: Use TLS (non-zero) when gRPC traffic crosses untrusted networks\n- **Internal cluster**: May use plaintext (0) for performance if network is isolated\n\n### Security\nPlaintext connections expose all inter-service communication to network-level eavesdropping."`
	UsePrometheusGRPCMetrics     bool          `key:"use_prometheus_grpc_metrics" desc:"Enable Prometheus metrics for gRPC" default:"false" category:"Global" usage:"Adds gRPC call metrics to Prometheus" type:"bool" longdesc:"### Purpose\nEnables Prometheus metrics collection for all gRPC method calls across all services.\n\n### How It Works\nInstruments gRPC clients and servers with method-level metrics: call counts, durations, error rates, and message sizes. Implemented via grpc-ecosystem/go-grpc-middleware/providers/prometheus in util/grpc_helper.go. Metrics exposed via PrometheusEndpoint for Prometheus scraping with labels: service, method, status_code.\n\n### Values\n- **true** - Enable gRPC metrics collection\n- **false** (default) - Metrics disabled\n\n### Recommendations\n- Enable for monitoring inter-service communication health, identifying slow methods, and detecting error spikes\n- Minimal overhead when enabled"`
	GRPCAdminAPIKey              string        `key:"grpc_admin_api_key" desc:"Admin API key for gRPC" default:"" category:"Global" usage:"Used for authenticated admin operations" type:"string" longdesc:"### Purpose\nAPI key for authenticating administrative gRPC operations on protected services (P2P, Legacy).\n\n### How It Works\nWhen set, required as x-api-key header for gRPC calls to admin endpoints. Implemented in util/grpc_helper.go via PasswordCredentials and checked by server-side interceptors. Protects operations like ban peer, unban peer, and get peer info.\n\n### Values\n- **empty** (default) - Admin API key requirement disabled (insecure)\n- **random string** - Strong authentication key (32+ characters recommended)\n\n### Security\n- Should be a strong random string (32+ characters)\n- Keep confidential\n- Empty value disables admin API key requirement (insecure for production)\n- Not encrypted in transit unless SecurityLevelGRPC is enabled\n\n### Warning\nLeaving this empty in production allows unauthenticated admin operations."`
	ChainCfgParams               *chaincfg.Params
	Policy                       *PolicySettings
	Kafka                        KafkaSettings
	Aerospike                    AerospikeSettings
	Alert                        AlertSettings
	Asset                        AssetSettings
	Block                        BlockSettings
	BlockPersister               BlockPersisterSettings
	BlockAssembly                BlockAssemblySettings
	BlockChain                   BlockChainSettings
	BlockValidation              BlockValidationSettings
	Validator                    ValidatorSettings
	Region                       RegionSettings
	Advertising                  AdvertisingSettings
	UtxoStore                    UtxoStoreSettings
	P2P                          P2PSettings
	Coinbase                     CoinbaseSettings
	SubtreeValidation            SubtreeValidationSettings
	Legacy                       LegacySettings
	Propagation                  PropagationSettings
	RPC                          RPCSettings
	Faucet                       FaucetSettings
	Dashboard                    DashboardSettings
	Pruner                       PrunerSettings
	GlobalBlockHeightRetention   uint32 `key:"global_blockHeightRetention" desc:"Number of blocks to retain data for (default: ~2 days)" default:"288" category:"Global" usage:"Higher values use more storage but allow deeper reorgs" type:"uint32" longdesc:"### Purpose\nControls the default number of blocks to retain data for across all services before pruning.\n\n### How It Works\nUsed as base value for service-specific retention calculations via UtxoStore.BlockHeightRetentionAdjustment and SubtreeValidation.BlockHeightRetentionAdjustment. Services call GetUtxoStoreBlockHeightRetention() and GetSubtreeValidationBlockHeightRetention() which add adjustments to this global value. Affects old blocks, transactions, UTXO history, and Merkle tree data.\n\n### Values\n- **288** (default) - Approximately 2 days of blockchain history (with 10-minute block target)\n- Higher values for deeper reorg support\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Deeper reorg handling, longer data availability | More storage consumption |\n| Lower | Reduced storage requirements | Limited reorg depth |\n\n### Recommendations\n- **288** (default) - Suitable for most deployments\n- Increase for archive nodes or environments requiring deeper history"`
}

// GetUtxoStoreBlockHeightRetention calculates the effective block height retention for UTXO store
// by adding the adjustment to the global value. Returns 0 if the result would be negative.
func (s *Settings) GetUtxoStoreBlockHeightRetention() uint32 {
	result := int64(s.GlobalBlockHeightRetention) + int64(s.UtxoStore.BlockHeightRetentionAdjustment)
	if result < 0 {
		return 0
	}

	return uint32(result)
}

// GetSubtreeValidationBlockHeightRetention calculates the effective block height retention for subtree validation
// by adding the adjustment to the global value. Returns 0 if the result would be negative.
func (s *Settings) GetSubtreeValidationBlockHeightRetention() uint32 {
	result := int64(s.GlobalBlockHeightRetention) + int64(s.SubtreeValidation.BlockHeightRetentionAdjustment)
	if result < 0 {
		return 0
	}

	return uint32(result)
}
