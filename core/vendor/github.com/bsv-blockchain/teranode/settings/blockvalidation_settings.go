package settings

import "time"

// BlockValidationSettings configures the block validation service.
type BlockValidationSettings struct {
	MaxRetries                                int           `key:"blockValidationMaxRetries" desc:"Maximum retry attempts for block validation" default:"3" category:"BlockValidation" usage:"Retries on transient failures" type:"int" longdesc:"### Purpose\nControls how many times block validation operations will retry on transient failures.\n\n### How It Works\n- Applies to transient failures like network timeouts or temporary service unavailability\n- Permanent failures (invalid blocks) fail immediately without retry\n- Each retry adds latency but improves reliability\n\n### Recommendations\n- **3** (default) - Provides reasonable reliability for most environments\n- Lower values for faster failure detection in stable environments\n- Higher values for unreliable networks"`
	RetrySleep                                time.Duration `key:"blockValidationRetrySleep" desc:"Sleep duration between validation retries" default:"1s" category:"BlockValidation" usage:"Backoff between retry attempts" type:"duration" longdesc:"### Purpose\nSets the wait time between block validation retry attempts.\n\n### How It Works\nAfter a transient failure, the service waits this duration before attempting again, allowing temporary issues to resolve.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Shorter | Faster recovery | Higher load during outages |\n| Longer | Reduced load | Slower recovery |\n\n### Recommendations\n- **1s** (default) - Good balance for most environments\n- Increase for systems with longer recovery times"`
	GRPCAddress                               string        `key:"blockvalidation_grpcAddress" desc:"gRPC address for Block Validation service" default:"localhost:8088" category:"BlockValidation" usage:"Address for inter-service communication" type:"string" longdesc:"### Purpose\nSpecifies the client connection address for the Block Validation gRPC service.\n\n### Format\n**host:port** - Where host is a hostname, IP address, or DNS name.\n\n### Examples\n- **localhost:8088** - Local development (default)\n- **blockvalidation.internal:8088** - Internal DNS\n- **10.0.1.50:8088** - Direct IP address\n\n### Recommendations\n- Use internal DNS or service mesh addresses in production\n- Use localhost only for local development"`
	GRPCListenAddress                         string        `key:"blockvalidation_grpcListenAddress" desc:"gRPC listen address for Block Validation service" default:":8088" category:"BlockValidation" usage:"Port for incoming gRPC connections" type:"string" longdesc:"### Purpose\nSpecifies the server binding address for the Block Validation gRPC service.\n\n### Format\n- **:port** - Binds to all network interfaces\n- **ip:port** - Binds to a specific interface\n\n### Examples\n- **:8088** - Listen on all interfaces (default)\n- **127.0.0.1:8088** - Listen only on localhost\n- **10.0.1.50:8088** - Listen on specific interface\n\n### Recommendations\n- Use **:port** format for containerized deployments\n- Bind to specific IP for security in multi-tenant environments"`
	KafkaWorkers                              int           `key:"blockvalidation_kafkaWorkers" desc:"Number of Kafka consumer workers" default:"0" category:"BlockValidation" usage:"0 = auto-scale" type:"int" longdesc:"### Purpose\nControls the number of goroutines consuming block validation Kafka messages.\n\n### How It Works\n- Each worker processes messages from Kafka partitions independently\n- Workers are distributed across available partitions\n\n### Values\n- **0** (default) - Automatic scaling based on partition count and system resources\n- **N > 0** - Fixed number of workers for deterministic resource allocation\n\n### Recommendations\n- Use **0** for most deployments to leverage auto-scaling\n- Set explicitly when you need predictable resource usage or debugging"`
	LocalSetTxMinedConcurrency                int           `key:"blockvalidation_localSetTxMinedConcurrency" desc:"Concurrency for setting transaction mined status" default:"8" category:"BlockValidation" usage:"Parallel tx status updates" type:"int" longdesc:"### Purpose\nControls the number of parallel workers updating transaction mined status after block validation.\n\n### How It Works\nAfter a block is validated, each transaction must be marked as mined. This setting controls how many transactions are updated in parallel.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster updates for large blocks | Higher database load |\n| Lower | Reduced database pressure | Slower status propagation |\n\n### Recommendations\n- **8** (default) - Good balance for most databases\n- Increase for high-performance storage systems\n- Decrease if database is a bottleneck"`
	MaxPreviousBlockHeadersToCheck            uint64        `key:"blockvalidation_maxPreviousBlockHeadersToCheck" desc:"Maximum previous headers to validate" default:"100" category:"BlockValidation" usage:"Header chain validation depth" type:"uint64" longdesc:"### Purpose\nLimits how many previous block headers are checked during header chain validation.\n\n### How It Works\n- Validates proof-of-work and merkle root for recent headers\n- Prevents excessive computation on long chains\n- Covers detection of chain reorganizations\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Detects deeper reorgs | More computation per validation |\n| Lower | Faster validation | May miss deep reorgs |\n\n### Recommendations\n- **100** (default) - Covers typical reorg scenarios\n- Increase if operating in adversarial network conditions"`
	MissingTransactionsBatchSize              int           `key:"blockvalidation_missingTransactionsBatchSize" desc:"Batch size for missing transaction fetches" default:"5000" category:"BlockValidation" usage:"Transactions per batch" type:"int" longdesc:"### Purpose\nControls how many missing transactions are fetched per batch during block validation.\n\n### How It Works\nWhen transactions are not found in cache, they are fetched from storage in batches to reduce round-trips while managing memory.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Larger | Fewer database round-trips | Higher memory usage |\n| Smaller | Lower memory usage | More database queries |\n\n### Recommendations\n- **5000** (default) - Balanced for most systems\n- Reduce if memory constrained\n- Increase for high-latency storage systems"`
	ProcessTxMetaUsingCacheBatchSize          int           `key:"blockvalidation_processTxMetaUsingCache_BatchSize" desc:"Batch size for cache-based metadata processing" default:"1024" category:"BlockValidation" usage:"Records per cache batch" type:"int" longdesc:"### Purpose\nControls how many transaction metadata records are processed per batch from cache.\n\n### How It Works\nTransaction metadata is read from cache in batches to optimize memory access patterns and reduce overhead.\n\n### Recommendations\n- **1024** (default) - Efficient for typical cache implementations\n- Adjust based on cache line sizes and memory architecture"`
	ProcessTxMetaUsingCacheConcurrency        int           `key:"blockvalidation_processTxMetaUsingCache_Concurrency" desc:"Concurrency for cache-based metadata processing" default:"32" category:"BlockValidation" usage:"Parallel cache workers" type:"int" longdesc:"### Purpose\nControls the number of parallel workers processing transaction metadata from cache.\n\n### How It Works\nMultiple goroutines process cached metadata concurrently. Cache operations are typically fast, allowing high concurrency.\n\n### Recommendations\n- **32** (default) - High throughput for typical cache performance\n- Increase for systems with very fast cache access\n- Decrease if experiencing cache contention"`
	ProcessTxMetaUsingCacheMissingTxThreshold int           `key:"blockvalidation_processTxMetaUsingCache_MissingTxThreshold" desc:"Missing transaction threshold for cache processing" default:"1" category:"BlockValidation" usage:"When to switch from cache to store" type:"int" longdesc:"### Purpose\nDefines when to switch from cache-based to store-based processing based on cache misses.\n\n### How It Works\nWhen processing transaction metadata, if cache misses exceed this threshold, the system falls back to store-based processing.\n\n### Values\n- **1** (default) - Fall back on any cache miss (strict)\n- **N > 1** - Tolerate N cache misses before switching\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Lower | Consistent performance | More store fallbacks |\n| Higher | Maximizes cache use | Potential for slow mixed-mode processing |"`
	ProcessTxMetaUsingStoreBatchSize          int           `key:"blockvalidation_processTxMetaUsingStore_BatchSize" desc:"Batch size for store-based metadata processing" default:"1024" category:"BlockValidation" usage:"Records per store batch" type:"int" longdesc:"### Purpose\nControls how many transaction metadata records are fetched per batch from persistent store.\n\n### How It Works\nWhen processing from store (instead of cache), records are fetched in batches to balance memory usage with database round-trips.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Larger | Fewer database queries | Higher memory per batch |\n| Smaller | Lower memory usage | More database overhead |\n\n### Recommendations\n- **1024** (default) - Good balance for most databases"`
	ProcessTxMetaUsingStoreConcurrency        int           `key:"blockvalidation_processTxMetaUsingStore_Concurrency" desc:"Concurrency for store-based metadata processing" default:"auto" category:"BlockValidation" usage:"Parallel store workers" type:"int" longdesc:"### Purpose\nControls the number of parallel workers processing transaction metadata from store.\n\n### How It Works\nMultiple goroutines query the persistent store concurrently to maximize throughput.\n\n### Values\n- **auto** (default) - Uses max(4, NumCPU/2) for automatic scaling\n- **N** - Fixed number of workers\n\n### Recommendations\n- Use **auto** for most deployments\n- Set explicitly for deterministic resource allocation or database connection limits"`
	ProcessTxMetaUsingStoreMissingTxThreshold int           `key:"blockvalidation_processTxMetaUsingStore_MissingTxThreshold" desc:"Missing transaction threshold for store processing" default:"1" category:"BlockValidation" usage:"Threshold for store fallback" type:"int" longdesc:"### Purpose\nDefines when to trigger alternative fetch strategies based on store misses.\n\n### How It Works\nWhen processing from store, if missing transactions exceed this threshold, alternative strategies (like peer fetch) are triggered.\n\n### Values\n- **1** (default) - Trigger alternatives on first miss\n- **N > 1** - Tolerate more misses before escalation\n\n### Recommendations\n- **1** is appropriate for most scenarios to ensure data completeness"`
	SkipCheckParentMined                      bool          `key:"blockvalidation_skipCheckParentMined" desc:"Skip parent mined status check" default:"false" category:"BlockValidation" usage:"TESTING ONLY" type:"bool" longdesc:"### Purpose\nSkips checking if parent block is mined before validating a child block.\n\n### Warning\n**TESTING ONLY** - Enabling this in production can cause chain inconsistencies and data corruption.\n\n### How It Works\nNormally, block validation verifies the parent block is mined before proceeding. This setting bypasses that check for testing scenarios.\n\n### Values\n- **false** (default) - Always verify parent is mined (required for production)\n- **true** - Skip parent check (testing only)"`
	SubtreeFoundChConcurrency                 int           `key:"blockvalidation_subtreeFoundChConcurrency" desc:"Concurrency for subtree found channel" default:"1" category:"BlockValidation" usage:"Parallel subtree notifications" type:"int" longdesc:"### Purpose\nControls parallel processing of subtree found notifications.\n\n### How It Works\nWhen subtrees are discovered during validation, notifications are processed by worker goroutines.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| 1 | Ordered processing | Lower throughput |\n| N > 1 | Higher throughput | Non-deterministic ordering |\n\n### Recommendations\n- **1** (default) - When notification ordering matters\n- Increase only if ordering is not critical and throughput is needed"`
	SubtreeValidationAbandonThreshold         int           `key:"blockvalidation_subtree_validation_abandon_threshold" desc:"Threshold for abandoning subtree validation" default:"1" category:"BlockValidation" usage:"Failures before abandoning" type:"int" longdesc:"### Purpose\nControls how many subtree validation failures are tolerated before abandoning block validation.\n\n### How It Works\nDuring block validation, if subtree validation fails, this threshold determines whether to continue trying or abandon the entire block.\n\n### Values\n- **1** (default) - Fail fast on first invalid subtree\n- **N > 1** - Allow N failures before abandoning\n\n### Recommendations\n- **1** is appropriate for most scenarios (fail fast)\n- Higher values may be useful for debugging or when transient failures are expected"`
	ValidateBlockSubtreesConcurrency          int           `key:"blockvalidation_validateBlockSubtreesConcurrency" desc:"Concurrency for subtree validation" default:"auto" category:"BlockValidation" usage:"Parallel subtree workers" type:"int" longdesc:"### Purpose\nControls the number of parallel workers validating merkle subtrees within a block.\n\n### How It Works\nSubtree validation involves both I/O (fetching data) and CPU (hashing) operations. Multiple workers can validate different subtrees concurrently.\n\n### Values\n- **auto** (default) - Uses max(4, NumCPU/2) for automatic scaling\n- **N** - Fixed number of workers\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster validation | More CPU and I/O contention |\n| Lower | Reduced resource usage | Slower validation |\n\n### Recommendations\n- Use **auto** for most deployments\n- Tune based on available CPU cores and storage IOPS"`
	ValidationMaxRetries                      int           `key:"blockvalidation_validation_max_retries" desc:"Maximum validation retry attempts" default:"3" category:"BlockValidation" usage:"Per-block retries" type:"int" longdesc:"### Purpose\nControls maximum retry attempts for individual block validation on transient failures.\n\n### How It Works\n- Applies to transient failures: network errors, temporary unavailability\n- Invalid blocks fail immediately without retry (no point retrying consensus failures)\n- Each retry uses the backoff duration between attempts\n\n### Recommendations\n- **3** (default) - Reasonable for most environments\n- Increase for unreliable networks\n- Decrease for faster failure detection"`
	ValidationRetrySleep                      time.Duration `key:"blockvalidation_validation_retry_sleep" desc:"Sleep between validation retries" default:"5s" category:"BlockValidation" usage:"Backoff between retries" type:"duration" longdesc:"### Purpose\nSets the base sleep duration between validation retry attempts.\n\n### How It Works\n- First retry waits this duration\n- Subsequent retries use exponential backoff (each wait is multiplied)\n- Allows dependent services time to recover from transient issues\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Shorter | Faster recovery | May retry before service recovers |\n| Longer | Better recovery chance | Slower overall progress |\n\n### Recommendations\n- **5s** (default) - Good balance for most services"`
	OptimisticMining                          bool          `key:"blockvalidation_optimistic_mining" desc:"Enable optimistic mining" default:"true" category:"BlockValidation" usage:"Mine before full validation" type:"bool" longdesc:"### Purpose\nAllows mining to proceed before full script validation completes, significantly reducing latency.\n\n### How It Works\n- Creates UTXOs and starts mining immediately upon block receipt\n- Full script validation continues in parallel\n- If validation fails, UTXOs are reverted\n- Reduces mining latency from seconds to milliseconds\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Enabled | Competitive mining latency | Risk of wasted hashpower on invalid blocks |\n| Disabled | No wasted work | Higher mining latency |\n\n### Recommendations\n- **true** (default) - Required for competitive mining operations\n- **false** - Only for ultra-conservative setups where latency is not critical"`
	IsParentMinedRetryMaxRetry                int           `key:"blockvalidation_isParentMined_retry_max_retry" desc:"Maximum retries for parent mined check" default:"45" category:"BlockValidation" usage:"Retries waiting for parent" type:"int" longdesc:"### Purpose\nControls retry attempts when checking if parent block is mined.\n\n### How It Works\nDuring rapid block arrival, the parent block may not be marked as mined immediately. This setting allows the child to wait for the parent status to propagate.\n\n### Timing\nWith default settings (45 retries, 20ms base, 4x multiplier), total wait time is approximately 10 seconds.\n\n### Recommendations\n- **45** (default) - Suitable for most systems\n- Increase for slow storage or high-latency systems\n- Works in conjunction with backoff multiplier and duration settings"`
	IsParentMinedRetryBackoffMultiplier       int           `key:"blockvalidation_isParentMined_retry_backoff_multiplier" desc:"Backoff multiplier for parent mined retries" default:"4" category:"BlockValidation" usage:"Exponential backoff factor" type:"int" longdesc:"### Purpose\nSets the exponential backoff multiplier between parent mined check retries.\n\n### How It Works\nEach retry waits longer than the previous, with wait time multiplied by this factor.\n\n### Example\nWith base 20ms and multiplier 4:\n- Retry 1: 20ms\n- Retry 2: 80ms\n- Retry 3: 320ms\n- Retry 4: 1280ms\n\n### Recommendations\n- **4** (default) - Aggressive backoff, good for most scenarios\n- Lower values (2-3) for more consistent retry timing\n- Higher values for longer exponential growth"`
	IsParentMinedRetryBackoffDuration         time.Duration `key:"blockvalidation_isParentMined_retry_backoff_duration" desc:"Base backoff for parent mined retries" default:"20ms" category:"BlockValidation" usage:"Initial retry delay" type:"duration" longdesc:"### Purpose\nSets the base duration for the first retry when checking parent mined status.\n\n### How It Works\n- First retry waits this duration\n- Subsequent retries multiply this by the backoff multiplier\n- Smaller values provide faster initial response\n\n### Recommendations\n- **20ms** (default) - Quick initial retry for fast systems\n- Increase for high-latency storage systems\n- Works with max retries and backoff multiplier to determine total wait time"`
	SubtreeGroupConcurrency                   int           `key:"blockvalidation_subtreeGroupConcurrency" desc:"Concurrency for subtree group processing" default:"1" category:"BlockValidation" usage:"Parallel subtree groups" type:"int" longdesc:"### Purpose\nControls parallel processing of subtree groups during validation.\n\n### How It Works\nSubtrees can be organized into groups. This setting controls how many groups are processed concurrently.\n\n### Values\n- **1** (default) - Sequential group processing\n- **N > 1** - Parallel group processing\n\n### Recommendations\n- **1** - When groups have dependencies or ordering requirements\n- Increase only when groups are independent and parallelism is beneficial"`
	BlockFoundChBufferSize                    int           `key:"blockvalidation_blockFoundCh_buffer_size" desc:"Buffer size for block found channel" default:"1000" category:"BlockValidation" usage:"Queue for incoming blocks" type:"int" longdesc:"### Purpose\nSets the buffer size for the channel receiving block found notifications.\n\n### How It Works\nWhen blocks are discovered, notifications are queued in this channel. A larger buffer handles burst arrivals without blocking the sender.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Larger | Handles bursts, no sender blocking | More memory usage |\n| Smaller | Lower memory | May block senders during bursts |\n\n### Recommendations\n- **1000** (default) - Suitable for typical network conditions\n- Increase for high-throughput scenarios with bursty block arrivals"`
	ValidationWarmupCount                     int           `key:"blockvalidation_validation_warmup_count" desc:"Blocks to pre-load on startup" default:"128" category:"BlockValidation" usage:"Cache warmup" type:"int" longdesc:"### Purpose\nControls how many recent blocks are pre-loaded into cache on startup.\n\n### How It Works\nOn service startup, recent blocks are loaded into cache to reduce cold-start latency for initial validations.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster initial validations | Longer startup time, more memory |\n| Lower | Faster startup | Cold cache for initial requests |\n\n### Recommendations\n- **128** (default) - Covers typical fork depths and reorg scenarios\n- Increase for systems with deep fork history requirements"`
	BatchMissingTransactions                  bool          `key:"blockvalidation_batch_missing_transactions" desc:"Batch missing transaction fetches" default:"false" category:"BlockValidation" usage:"Enable transaction batching" type:"bool" longdesc:"### Purpose\nEnables batching of missing transaction fetches instead of individual queries.\n\n### How It Works\n- When disabled, each missing transaction is fetched individually\n- When enabled, missing transactions are collected and fetched in batches\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Enabled | Reduced database overhead | Latency for batch collection |\n| Disabled | Lower per-request latency | More database queries |\n\n### Recommendations\n- **false** (default) - Optimized for low-latency operation\n- Enable when database query overhead is the bottleneck"`
	CheckSubtreeFromBlockTimeout              time.Duration `key:"blockvalidation_check_subtree_from_block_timeout" desc:"Timeout for subtree-from-block check" default:"5m" category:"BlockValidation" usage:"Maximum wait for subtree" type:"duration" longdesc:"### Purpose\nSets the maximum time to wait when checking subtrees from block data.\n\n### How It Works\nWhen validating subtrees within a block, this timeout limits how long the operation can take. Exceeding this timeout triggers retry logic.\n\n### Recommendations\n- **5m** (default) - Allows for processing very large blocks\n- Increase for systems with slow storage or extremely large blocks\n- Decrease to fail faster if blocks should process quickly"`
	CheckSubtreeFromBlockRetries              int           `key:"blockvalidation_check_subtree_from_block_retries" desc:"Retries for subtree-from-block check" default:"5" category:"BlockValidation" usage:"Retry attempts" type:"int" longdesc:"### Purpose\nControls retry attempts for subtree-from-block operations.\n\n### How It Works\nWhen subtree checking fails (timeout or transient error), the operation is retried up to this limit with backoff between attempts.\n\n### Recommendations\n- **5** (default) - Reasonable persistence for transient failures\n- Increase for unreliable storage systems\n- Works with backoff duration to determine total retry window"`
	CheckSubtreeFromBlockRetryBackoffDuration time.Duration `key:"blockvalidation_check_subtree_from_block_retry_backoff_duration" desc:"Backoff for subtree-from-block retries" default:"30s" category:"BlockValidation" usage:"Delay between retries" type:"duration" longdesc:"### Purpose\nSets the backoff duration between subtree-from-block retry attempts.\n\n### How It Works\nAfter a failed subtree check, the system waits this duration before retrying, allowing transient issues to resolve.\n\n### Recommendations\n- **30s** (default) - Generous time for recovery from transient issues\n- Decrease for faster retry cycles if issues resolve quickly\n- Increase for systems with longer recovery times"`
	SecretMiningThreshold                     uint32        `key:"blockvalidation_secret_mining_threshold" desc:"Threshold for secret mining detection" default:"99" category:"BlockValidation" usage:"Blocks behind before rejection" type:"uint32" longdesc:"### Purpose\nDetects potential secret mining attacks where peers withhold blocks.\n\n### How It Works\n- Compares a peers chain to the common ancestor\n- If peer is more than this many blocks behind, treated as potential attack\n- Prevents deep reorganizations that could invalidate spent coinbase transactions\n\n### Why 99?\nDefault value is **coinbase maturity - 1**. Coinbase outputs cannot be spent until 100 confirmations. A reorg deeper than 99 blocks could reverse already-spent coinbase transactions.\n\n### Recommendations\n- **99** (default) - Aligned with coinbase maturity rules\n- Changing this value has security implications"`
	PreviousBlockHeaderCount                  uint64        `key:"blockvalidation_previous_block_header_count" desc:"Previous headers to track" default:"100" category:"BlockValidation" usage:"Header history for validation" type:"uint64" longdesc:"### Purpose\nControls how many previous block headers are maintained in memory for validation.\n\n### How It Works\nRecent block headers are kept in memory to support:\n- Chain validation\n- Reorg detection\n- Fork resolution\n\n### Recommendations\n- **100** (default) - Covers typical validation and reorg scenarios\n- Increase if expecting deeper forks or longer validation chains\n- Lower values reduce memory but may require more storage lookups"`
	MaxBlocksBehindBlockAssembly              int           `key:"blockvalidation_maxBlocksBehindBlockAssembly" desc:"Maximum blocks behind Block Assembly" default:"20" category:"BlockValidation" usage:"Sync tolerance" type:"int" longdesc:"### Purpose\nSets the maximum blocks Block Validation can lag behind Block Assembly.\n\n### How It Works\n- Block Assembly may produce blocks faster than Block Validation can process\n- When this threshold is exceeded, catchup mode or waiting is triggered\n- Prevents unbounded queue growth between services\n\n### Recommendations\n- **20** (default) - Reasonable buffer for processing delays\n- Increase for systems with variable validation times\n- Decrease to maintain tighter synchronization"`
	PeriodicProcessingInterval                time.Duration `key:"blockvalidation_periodic_processing_interval" desc:"Interval for periodic processing" default:"1m" category:"BlockValidation" usage:"Background task frequency" type:"duration" longdesc:"### Purpose\nSets the interval for periodic background processing tasks.\n\n### Tasks Performed\n- Checking mined status of pending blocks\n- Cache cleanup and maintenance\n- Resource cleanup and garbage collection\n\n### Recommendations\n- **1m** (default) - Regular maintenance without excessive overhead\n- Decrease for faster status updates (more CPU usage)\n- Increase for reduced background activity"`
	RecentBlockIDsLimit                       uint64        `key:"blockvalidation_recentBlockIDsLimit" desc:"Maximum recent block IDs to load" default:"50000" category:"BlockValidation" usage:"Memory limit for recent block IDs" type:"uint64" longdesc:"### Purpose\nLimits the number of recent block IDs loaded into memory for double-spend checking.\n\n### How It Works\nRecent block IDs are kept in memory to support fast double-spend detection. This setting prevents unbounded memory growth.\n\n### Recommendations\n- **50000** (default) - Covers typical scenarios\n- Increase for deeper history requirements\n- Decrease for memory-constrained environments"`
	// Catchup configuration
	CatchupChBufferSize             int           `key:"blockvalidation_catchupCh_buffer_size" desc:"Buffer size for catchup channel" default:"100" category:"BlockValidation" usage:"Queue for catchup blocks" type:"int" longdesc:"### Purpose\nSets the buffer size for the channel receiving catchup block notifications.\n\n### How It Works\nDuring catchup mode, blocks are queued for processing. This buffer prevents blocking when multiple blocks arrive quickly.\n\n### Recommendations\n- **100** (default) - Handles typical catchup scenarios\n- Increase if experiencing backpressure during large syncs"`
	UseCatchupWhenBehind            bool          `key:"blockvalidation_useCatchupWhenBehind" desc:"Enable automatic catchup mode" default:"false" category:"BlockValidation" usage:"Auto-switch to catchup" type:"bool" longdesc:"### Purpose\nAutomatically switches to optimized catchup mode when the node falls behind the network.\n\n### How It Works\n- Monitors chain height relative to known network tip\n- When behind by threshold, switches to catchup mode\n- Catchup uses batch fetching and quick validation for faster sync\n- Returns to normal mode once caught up\n\n### Values\n- **false** (default) - Always use normal validation\n- **true** - Enable automatic catchup mode switching\n\n### Recommendations\n- Enable for nodes that may experience periods of being offline\n- Keep disabled for always-connected mining nodes"`
	CatchupConcurrency              int           `key:"blockvalidation_catchupConcurrency" desc:"Concurrency for catchup operations" default:"auto" category:"BlockValidation" usage:"Parallel catchup workers" type:"int" longdesc:"### Purpose\nControls the number of concurrent operations during catchup mode.\n\n### How It Works\nMultiple blocks can be fetched and validated in parallel to accelerate sync.\n\n### Values\n- **auto** (default) - Uses max(4, NumCPU/2)\n- **N** - Fixed number of concurrent operations\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster catchup | More CPU, memory, and network usage |\n| Lower | Lower resource usage | Slower catchup |\n\n### Recommendations\n- Use **auto** for most deployments\n- Set explicitly for resource-constrained environments"`
	CatchupMaxRetries               int           `key:"blockvalidation_catchup_max_retries" desc:"Maximum catchup retry attempts" default:"3" category:"BlockValidation" usage:"Retries for catchup operations" type:"int" longdesc:"### Purpose\nControls retry attempts for catchup operations before giving up.\n\n### How It Works\n- Each retry selects a different peer for data fetching\n- Helps recover from individual peer failures\n- After exhausting retries, catchup operation fails\n\n### Recommendations\n- **3** (default) - Reasonable for networks with multiple peers\n- Increase for sparse networks with fewer peer options"`
	CatchupIterationTimeout         int           `key:"blockvalidation_catchup_iteration_timeout" desc:"Timeout per catchup iteration in seconds" default:"30" category:"BlockValidation" usage:"Per-iteration time limit" type:"int" longdesc:"### Purpose\nSets the timeout in seconds for each catchup iteration.\n\n### Scope\nApplies to individual operations within catchup:\n- Header fetch\n- Block fetch\n- Block validation\n\n### Recommendations\n- **30** (default) - Reasonable for most network conditions\n- Increase for slow networks or large blocks\n- Decrease to fail faster and try different peers"`
	CatchupOperationTimeout         int           `key:"blockvalidation_catchup_operation_timeout" desc:"Total catchup operation timeout in seconds" default:"300" category:"BlockValidation" usage:"Maximum total catchup time" type:"int" longdesc:"### Purpose\nSets the total timeout for the entire catchup operation.\n\n### How It Works\nThis is a backstop timeout that limits total catchup time including all retries and iterations. Prevents runaway operations from consuming resources indefinitely.\n\n### Recommendations\n- **300** (default) - 5 minutes, suitable for most sync scenarios\n- Increase for very large sync operations\n- Decrease if catchup should fail faster"`
	CatchupMaxAccumulatedHeaders    int           `key:"blockvalidation_max_accumulated_headers" desc:"Maximum accumulated headers during catchup" default:"100000" category:"BlockValidation" usage:"Memory limit for headers" type:"int" longdesc:"### Purpose\nLimits headers accumulated in memory during catchup to prevent exhaustion.\n\n### How It Works\n- Headers are collected in memory during catchup\n- When this limit is reached, batch processing is triggered\n- Prevents memory exhaustion during large sync operations\n\n### Memory Usage\n100000 headers is approximately 8MB of memory.\n\n### Recommendations\n- **100000** (default) - Safe for most systems\n- Reduce for memory-constrained environments\n- Increase for systems with ample memory to reduce batch processing frequency"`
	CatchupCheckpointHash           string        `key:"blockvalidation_catchup_checkpoint_hash" desc:"Optional checkpoint block hash to use during catchup" default:"" category:"BlockValidation" usage:"Override automatic checkpoint selection" type:"string" longdesc:"### Purpose\nOverrides automatic checkpoint selection during catchup with a specific block hash.\n\n### How It Works\nDuring catchup, the system normally selects a checkpoint automatically based on chain config. Setting this value forces catchup to use the specified checkpoint instead.\n\n### Format\nHex-encoded block hash string.\n\n### Values\n- **empty** (default) - Use automatic checkpoint selection\n- **hash string** - Use specified checkpoint hash\n\n### Recommendations\n- Leave empty for normal operation\n- Set explicitly only when testing specific catchup scenarios or recovering from known-good checkpoints"`
	CatchupCheckpointHeight         int32         `key:"blockvalidation_catchup_checkpoint_height" desc:"Optional checkpoint block height to use during catchup" default:"0" category:"BlockValidation" usage:"Override automatic checkpoint selection" type:"int32" longdesc:"### Purpose\nOverrides automatic checkpoint height selection during catchup with a specific block height.\n\n### How It Works\nWorks in conjunction with CatchupCheckpointHash. When both are set, catchup will validate from this specific checkpoint.\n\n### Values\n- **0** (default) - Use automatic checkpoint selection\n- **N > 0** - Use specified checkpoint height\n\n### Recommendations\n- Leave at 0 for normal operation\n- Set explicitly only when CatchupCheckpointHash is also specified\n- Must match the actual height of the checkpoint hash"`
	CatchupAllowQuickValidation     bool          `key:"blockvalidation_catchup_allow_quick_validation" desc:"Allow quick validation during catchup" default:"false" category:"BlockValidation" usage:"Enable quick validation mode" type:"bool" longdesc:"### Purpose\nEnables quick validation mode during catchup for blocks verified by checkpoints.\n\n### How It Works\n- Only applies to blocks at or below verified checkpoint heights\n- Bypasses full transaction validation since checkpoints guarantee validity\n- Creates and spends UTXOs directly without validator service calls\n- Skips writing subtree metadata files (.subtreemeta)\n- Significantly faster than normal validation for trusted blocks\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Enabled (true) | Much faster catchup for checkpointed blocks | No transaction validation for those blocks |\n| Disabled (false) | Full validation even for checkpointed blocks | Slower catchup |\n\n### Recommendations\n- **false** (default) - Full validation for all blocks\n- Enable for faster catchup when you trust the checkpoint verification"`
	CircuitBreakerFailureThreshold  int           `key:"blockvalidation_circuit_breaker_failure_threshold" desc:"Failures before circuit opens" default:"5" category:"BlockValidation" usage:"Peer failure threshold" type:"int" longdesc:"### Purpose\nSets the consecutive failure count before opening the circuit breaker for a peer.\n\n### How It Works\nCircuit breaker pattern protects against persistently failing peers:\n- **Closed** - Normal operation, requests go through\n- **Open** - After N failures, requests blocked for cooldown period\n- **Half-Open** - After cooldown, limited requests test recovery\n\n### Recommendations\n- **5** (default) - Tolerates transient errors while catching persistent issues\n- Increase for more tolerance of flaky peers\n- Decrease for faster isolation of problematic peers"`
	CircuitBreakerSuccessThreshold  int           `key:"blockvalidation_circuit_breaker_success_threshold" desc:"Successes before circuit closes" default:"2" category:"BlockValidation" usage:"Recovery threshold" type:"int" longdesc:"### Purpose\nSets the consecutive success count required to close the circuit after recovery.\n\n### How It Works\nWhen in half-open state (testing recovery), this many consecutive successes are required before fully restoring the peer to normal operation.\n\n### Recommendations\n- **2** (default) - Requires proof of recovery without excessive testing\n- Increase for more confidence before restoring peers\n- Decrease for faster recovery (but risk of premature restoration)"`
	CircuitBreakerTimeoutSeconds    int           `key:"blockvalidation_circuit_breaker_timeout_seconds" desc:"Seconds before circuit recovery" default:"30" category:"BlockValidation" usage:"Cooldown period" type:"int" longdesc:"### Purpose\nSets how long the circuit breaker remains open before allowing recovery attempts.\n\n### How It Works\nAfter opening due to failures, the circuit breaker waits this long before transitioning to half-open state, where recovery is tested.\n\n### Recommendations\n- **30** (default) - Reasonable cooldown for most transient issues\n- Increase for issues that take longer to resolve\n- Decrease for faster recovery attempts (but may retry too soon)"`
	FetchLargeBatchSize             int           `key:"blockvalidation_fetch_large_batch_size" desc:"Blocks per fetch batch" default:"100" category:"BlockValidation" usage:"HTTP batch size" type:"int" longdesc:"### Purpose\nControls how many blocks are requested in a single HTTP batch during catchup.\n\n### How It Works\nDuring catchup, blocks are fetched in batches to reduce HTTP overhead. This setting controls batch size.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Larger | Fewer HTTP requests | Longer per-request time, more memory |\n| Smaller | Faster individual requests | More HTTP overhead |\n\n### Recommendations\n- **100** (default) - Matches typical peer limits\n- Adjust based on peer capabilities and network conditions"`
	FetchNumWorkers                 int           `key:"blockvalidation_fetch_num_workers" desc:"Number of fetch workers" default:"1" category:"BlockValidation" usage:"Parallel fetchers" type:"int" longdesc:"### Purpose\nControls the number of parallel workers fetching blocks during catchup.\n\n### How It Works\nMultiple workers can fetch different block ranges simultaneously, potentially speeding up catchup.\n\n### Values\n- **1** (default) - Sequential fetching\n- **N > 1** - Parallel fetching from multiple ranges\n\n### Recommendations\n- **1** - Simple and reliable, works with all peers\n- Increase only if peer supports parallel requests and bandwidth allows"`
	FetchBufferSize                 int           `key:"blockvalidation_fetch_buffer_size" desc:"Buffer size for fetch channels" default:"50" category:"BlockValidation" usage:"Work queue buffer" type:"int" longdesc:"### Purpose\nSets the buffer size for channels between fetch pipeline stages.\n\n### How It Works\nThe fetch pipeline has multiple stages (request, receive, process). This buffer allows stages to work at different rates without blocking.\n\n### Recommendations\n- **50** (default) - Provides backpressure without blocking\n- Increase for higher throughput with more memory usage\n- Decrease for tighter flow control"`
	SubtreeFetchConcurrency         int           `key:"blockvalidation_subtree_fetch_concurrency" desc:"Concurrent subtree fetches" default:"8" category:"BlockValidation" usage:"Parallel subtree fetching" type:"int" longdesc:"### Purpose\nControls maximum concurrent subtree fetches per block during catchup.\n\n### How It Works\nBlocks contain multiple subtrees that can be fetched in parallel. This setting limits concurrent fetches to manage peer load.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster subtree retrieval | Higher peer and network load |\n| Lower | Lower resource usage | Slower subtree retrieval |\n\n### Recommendations\n- **8** (default) - Good balance for most scenarios\n- Adjust based on peer capabilities and network bandwidth"`
	ExtendTransactionTimeout        time.Duration `key:"blockvalidation_extend_transaction_timeout" desc:"Timeout for extending transactions" default:"120s" category:"BlockValidation" usage:"Maximum wait for parent lookup" type:"duration" longdesc:"### Purpose\nSets the maximum time to wait when extending transaction inputs.\n\n### How It Works\nExtending a transaction involves fetching parent outputs to validate inputs. This timeout limits how long to wait for those lookups.\n\n### Recommendations\n- **120s** (default) - Handles slow storage systems\n- Decrease for faster failure detection with responsive storage\n- Increase for very high-latency storage systems"`
	GetBlockTransactionsConcurrency int           `key:"blockvalidation_get_block_transactions_concurrency" desc:"Concurrent transaction fetches" default:"64" category:"BlockValidation" usage:"Parallel transaction resolution" type:"int" longdesc:"### Purpose\nLimits concurrent transaction fetches from storage during block validation.\n\n### How It Works\nWhen validating a block, many transactions may need to be fetched. This setting controls parallelism to maximize throughput without overwhelming storage.\n\n### Recommendations\n- **64** (default) - High throughput for I/O-bound operations\n- Adjust based on storage system capabilities\n- Reduce if storage becomes a bottleneck"`
	NearForkThreshold               int           `key:"blockvalidation_near_fork_threshold" desc:"Threshold for near fork classification" default:"0" category:"BlockValidation" usage:"0 = coinbase_maturity/2" type:"int" longdesc:"### Purpose\nClassifies forks as near or deep based on block height difference.\n\n### How It Works\n- **Near forks** - Within threshold, get higher processing priority\n- **Deep forks** - Beyond threshold, lower priority\n\n### Values\n- **0** (default) - Uses coinbase_maturity/2 (typically 50 blocks)\n- **N > 0** - Fixed threshold of N blocks\n\n### Recommendations\n- **0** - Automatic, aligned with coinbase maturity\n- Set explicitly only if custom fork prioritization is needed"`
	MaxParallelForks                int           `key:"blockvalidation_max_parallel_forks" desc:"Maximum parallel fork processing" default:"4" category:"BlockValidation" usage:"Concurrent fork workers" type:"int" longdesc:"### Purpose\nLimits the number of competing forks processed in parallel.\n\n### How It Works\nWhen multiple chain forks exist, they are processed concurrently up to this limit. Each fork requires memory for block cache and chain state.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster fork resolution | More memory usage |\n| Lower | Lower memory | Slower multi-fork scenarios |\n\n### Recommendations\n- **4** (default) - Handles typical fork scenarios\n- Increase for adversarial conditions with many competing chains"`
	MaxTrackedForks                 int           `key:"blockvalidation_max_tracked_forks" desc:"Maximum tracked forks" default:"1000" category:"BlockValidation" usage:"Total forks in memory" type:"int" longdesc:"### Purpose\nLimits the total number of forks tracked in memory.\n\n### How It Works\nIncludes all fork states:\n- Active forks being processed\n- Stale forks pending cleanup\n- Queued forks awaiting processing\n\n### Security\nPrevents memory exhaustion from fork spam attacks where adversaries create many competing chains.\n\n### Recommendations\n- **1000** (default) - Prevents memory exhaustion while allowing legitimate forks\n- Reduce for memory-constrained environments\n- Increase only with careful memory monitoring"`
	// Pipeline processing settings
	SubtreeBatchSize             int `key:"blockvalidation_subtree_batch_size" desc:"Subtrees to process per batch in quick validation" default:"16" category:"BlockValidation" usage:"Subtree batch size" type:"int" longdesc:"### Purpose\nControls how many subtrees are processed together in a single batch during quick validation mode.\n\n### How It Works\nQuick validation processes subtrees in batches to optimize CPU cache locality and memory access patterns. Larger batches improve throughput but increase memory usage.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Larger | Better throughput, fewer context switches | Higher memory usage |\n| Smaller | Lower memory footprint | More overhead from batch transitions |\n\n### Recommendations\n- **16** (default) - Good balance for most systems\n- Increase for systems with large CPU caches and available memory\n- Decrease for memory-constrained environments"`
	SubtreeBatchPrefetchDepth    int `key:"blockvalidation_subtree_batch_prefetch_depth" desc:"Number of batches to prefetch ahead in pipeline" default:"2" category:"BlockValidation" usage:"Pipeline prefetch depth (0=sequential)" type:"int" longdesc:"### Purpose\nEnables pipeline prefetching by loading future batches while processing current ones.\n\n### How It Works\n- **0** - Sequential processing, no prefetching\n- **N > 0** - Pipeline processes N batches ahead\n- Prefetching overlaps I/O with computation for better throughput\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| 0 | Predictable memory usage | No I/O overlap |\n| Higher | Better I/O hiding, faster processing | More memory, potential wasted work on failure |\n\n### Recommendations\n- **2** (default) - Provides good I/O overlap without excessive memory\n- Increase for high-latency storage systems\n- Set to 0 for memory-constrained or debugging scenarios"`
	SubtreeBatchWriteConcurrency int `key:"blockvalidation_subtree_batch_write_concurrency" desc:"Concurrent subtree file writes per batch" default:"64" category:"BlockValidation" usage:"Parallel subtree writes" type:"int" longdesc:"### Purpose\nControls the number of subtree files written concurrently during batch processing.\n\n### How It Works\nSubtree writes can be performed in parallel to maximize storage throughput. This setting limits concurrency to prevent overwhelming the storage system.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster writes, better I/O utilization | More memory, potential storage contention |\n| Lower | Reduced resource usage | Slower batch completion |\n\n### Recommendations\n- **64** (default) - High throughput for typical storage systems\n- Reduce if experiencing storage bottlenecks\n- Increase for high-performance parallel storage (e.g., NVMe RAID)"`
	// Dynamic peer switching and parallel fetching
	CatchupMinThroughputKBps    int  `key:"blockvalidation_catchup_min_throughput_kbps" desc:"Minimum throughput in KB/s before switching peers" default:"100" category:"BlockValidation" usage:"Throughput threshold in KB/s" type:"int" longdesc:"### Purpose\nSets the minimum acceptable throughput threshold for peer connections during catchup.\n\n### How It Works\nDuring catchup, throughput is monitored continuously. If throughput falls below this threshold, the system switches to a different peer to maintain sync speed.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Ensures faster sync | May exhaust peer options on slower networks |\n| Lower | More tolerant of network conditions | Slower sync with poor peers |\n\n### Recommendations\n- **100** (default) - 100 KB/s minimum acceptable rate\n- Increase for networks with consistently high bandwidth\n- Decrease for constrained networks where peer options are limited"`
	CatchupParallelFetchEnabled bool `key:"blockvalidation_catchup_parallel_fetch_enabled" desc:"Enable parallel fetching from multiple peers" default:"true" category:"BlockValidation" usage:"Fetch from multiple peers simultaneously" type:"bool" longdesc:"### Purpose\nEnables simultaneous block fetching from multiple peers during catchup for faster sync.\n\n### How It Works\n- When enabled, different block ranges are fetched from different peers in parallel\n- Significantly accelerates catchup by utilizing multiple network connections\n- Requires sufficient peers and network bandwidth\n\n### Values\n- **true** (default) - Enable parallel fetching\n- **false** - Sequential fetching from single peer\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Enabled | Faster catchup | Higher network and CPU usage |\n| Disabled | Lower resource usage, simpler logic | Slower catchup |\n\n### Recommendations\n- Enable for production nodes that need fast catchup\n- Disable for bandwidth-limited environments or debugging"`
	CatchupParallelFetchWorkers int  `key:"blockvalidation_catchup_parallel_fetch_workers" desc:"Number of parallel fetch workers" default:"3" category:"BlockValidation" usage:"Number of concurrent peer connections" type:"int" longdesc:"### Purpose\nControls how many peers are used simultaneously for parallel block fetching during catchup.\n\n### How It Works\nEach worker fetches blocks from a different peer concurrently. More workers increase throughput but require more resources.\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster catchup if peers available | More CPU, memory, network bandwidth |\n| Lower | Lower resource usage | Slower catchup |\n\n### Recommendations\n- **3** (default) - Good balance for most networks\n- Increase if you have many reliable peers and available resources\n- Decrease for resource-constrained environments or limited peer availability"`
}
