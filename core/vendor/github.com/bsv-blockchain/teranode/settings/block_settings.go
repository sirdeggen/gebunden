package settings

import (
	"net/url"
	"time"
)

// BlockSettings configures block-related parameters.
type BlockSettings struct {
	MinedCacheMaxMB                       int           `key:"blockMinedCacheMaxMB" desc:"Maximum size of mined block cache in MB" default:"256" category:"Block" usage:"Memory limit for block cache" type:"int" longdesc:"### Purpose\nControls the maximum memory allocated for caching recently mined blocks. Improves performance when serving block data to peers and responding to RPC queries.\n\n### How It Works\n- Stores recently mined blocks in memory for fast access\n- Evicts oldest entries when the memory limit is reached\n- Reduces disk I/O for frequently accessed blocks\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Better cache hit rate | More memory usage |\n| Lower | Less memory usage | More disk reads |\n\n### Recommendations\n- **256 MB** (default) - Suitable for most deployments\n- Increase for nodes serving many concurrent peers or with high query volume\n- Decrease in memory-constrained environments"`
	CheckDuplicateTransactionsConcurrency int           `key:"block_checkDuplicateTransactionsConcurrency" desc:"Concurrency for duplicate transaction checks" default:"-1" category:"Block" usage:"-1 = NumCPU" type:"int" longdesc:"### Purpose\nControls the number of parallel workers checking for duplicate transactions within blocks. Duplicate checking prevents the same transaction from appearing multiple times in a block, which would be a consensus violation.\n\n### How It Works\n- Workers scan transactions in parallel to detect duplicates\n- Each worker processes a subset of the block transactions\n- Results are aggregated to identify any duplicates\n\n### Values\n- **-1** (default) - Uses runtime.NumCPU() for automatic scaling\n- **Positive value** - Sets an explicit worker limit\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster validation of large blocks | More CPU usage |\n| Lower | Reduced CPU load | Slower validation |\n\n### Recommendations\n- Use default (-1) for most deployments\n- Resource-constrained environments may benefit from explicit lower values"`
	GetAndValidateSubtreesConcurrency     int           `key:"block_getAndValidateSubtreesConcurrency" desc:"Concurrency for subtree fetching and validation" default:"-1" category:"Block" usage:"-1 = NumCPU" type:"int" longdesc:"### Purpose\nControls the number of parallel workers fetching and validating merkle subtrees during block validation. Subtree validation verifies the integrity of merkle tree segments that make up a block, ensuring all transactions are correctly included.\n\n### How It Works\n- Workers fetch subtrees from remote DataHubs in parallel\n- Each subtree is validated for correct merkle hash computation\n- This is I/O intensive as it requires network fetches\n\n### Values\n- **-1** (default) - Uses runtime.NumCPU() for automatic scaling\n- **Positive value** - Sets an explicit worker limit\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster validation | Increased network usage |\n| Lower | Reduced bandwidth consumption | Slower validation |\n\n### Recommendations\n- Balance with available bandwidth and DataHub capacity\n- Monitor network utilization when adjusting this value"`
	KafkaWorkers                          int           `key:"block_kafkaWorkers" desc:"Number of Kafka workers for block processing" default:"0" category:"Block" usage:"0 = auto-scale" type:"int" longdesc:"### Purpose\nControls the number of goroutines consuming block-related Kafka messages. Enables distributed block processing across the system.\n\n### How It Works\n- Each worker consumes messages from block-related Kafka topics\n- Workers process new blocks and subtrees in parallel\n- Messages are distributed across workers based on partition assignment\n\n### Values\n- **0** (default) - Automatic scaling based on partition count and system resources\n- **Positive value** - Explicit worker count for deterministic resource allocation\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Increased parallelism | More memory and CPU usage |\n| Lower | Reduced resource usage | Potential processing bottleneck |\n\n### Recommendations\n- Use default (0) for automatic scaling in most deployments\n- Set explicitly when you need predictable resource allocation"`
	ValidOrderAndBlessedConcurrency       int           `key:"block_validOrderAndBlessedConcurrency" desc:"Concurrency for order and blessing validation" default:"-1" category:"Block" usage:"-1 = NumCPU" type:"int" longdesc:"### Purpose\nControls the number of parallel workers validating transaction ordering and blessed status within blocks. Ensures transactions are properly ordered according to their dependencies and that blessed transactions (accepted by the miner) are correctly marked.\n\n### How It Works\n- Workers validate transaction ordering in parallel\n- Checks that dependent transactions appear after their dependencies\n- Verifies blessed status is consistent with miner acceptance\n\n### Values\n- **-1** (default) - Uses runtime.NumCPU() for automatic scaling\n- **Positive value** - Sets an explicit worker limit\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster validation of large blocks | More CPU usage |\n| Lower | Reduced CPU usage | Slower validation |\n\n### Recommendations\n- Use default (-1) for automatic scaling based on available CPUs"`
	MaxSize                               int           `key:"blockmaxsize" desc:"Maximum block size in bytes" default:"4294967296" category:"Block" usage:"4GB default (BSV)" type:"int" longdesc:"### Purpose\nDefines the upper limit for block sizes that this node will accept. Follows BSV unbounded scaling philosophy while providing a practical upper bound.\n\n### How It Works\n- Blocks exceeding this size are rejected during validation\n- Affects memory requirements during block processing\n- Acts as a safeguard against malformed giant blocks\n\n### Values\n- **4294967296** (default) - 4 GB, the standard BSV limit\n- Custom values should match network consensus\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher limit | Accepts larger blocks | Requires more memory |\n| Lower limit | Lower memory requirements | Rejects valid large blocks, may cause forks |\n\n### Recommendations\n**Warning**: This value must match network consensus. Nodes with different limits may fork from the network.\n\nTeranode is designed for unbounded blocks. This limit primarily prevents malformed giant blocks rather than restricting legitimate block sizes."`
	BlockStore                            *url.URL      `key:"blockstore" desc:"URL for block storage" default:"file://./data/blockstore" category:"Block" usage:"Where blocks are persisted" type:"url" longdesc:"### Purpose\nDefines where block data is persisted, including raw block content and merkle tree structures.\n\n### Format\n- **file://** - Local filesystem storage (e.g., file://./data/blockstore)\n- **s3://** - Cloud storage for distributed deployments\n\n### Trade-offs\n| Backend | Benefit | Drawback |\n|---------|---------|----------|\n| file:// | Low latency, simple setup | Single machine, manual backups |\n| s3:// | Distributed, built-in replication | Higher latency, network dependency |\n\n### Recommendations\n- **Development** - Use file:// for simplicity\n- **Production** - Consider s3:// for horizontal scaling\n- **Critical data** - Ensure backups for file:// or enable replication for s3://\n\nPerformance varies significantly between backends. Test thoroughly before production deployment."`
	FailFastValidation                    bool          `key:"blockvalidation_fail_fast_validation" desc:"Stop validation on first error" default:"true" category:"Block" usage:"Enable for production" type:"bool" longdesc:"### Purpose\nControls whether block validation stops immediately upon finding the first invalid transaction. Optimizes validation by avoiding unnecessary work once a block is known to be invalid.\n\n### How It Works\n- **Enabled** - Validation stops at the first error, block is rejected\n- **Disabled** - Validation continues to find all errors in the block\n\n### Values\n- **true** (default) - Stop on first error (production mode)\n- **false** - Continue to find all errors (debug mode)\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Enabled | Faster rejection of invalid blocks | Less detailed error info |\n| Disabled | Comprehensive error reporting | Slower validation |\n\n### Recommendations\n- **Production** - Keep enabled for efficiency\n- **Debugging** - Disable to identify all validation errors in problematic blocks\n\nInvalid blocks are rejected and reported regardless of this setting."`
	FinalizeBlockValidationConcurrency    int           `key:"blockvalidation_finalizeBlockValidationConcurrency" desc:"Concurrency for block finalization" default:"8" category:"Block" usage:"Parallel finalization workers" type:"int" longdesc:"### Purpose\nControls parallelism for the finalization phase that occurs after a block passes validation.\n\n### How It Works\n- Finalization writes validated blocks to persistent storage\n- Updates indexes and metadata for the new block\n- Workers operate in parallel to maximize I/O throughput\n\n### Values\n- **8** (default) - Good parallelism for typical storage systems\n- **Higher values** - Better utilization of fast storage (NVMe, SSD arrays)\n- **Lower values** - Reduced I/O pressure for slower storage\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster finalization | More I/O load |\n| Lower | Reduced storage pressure | Slower finalization |\n\n### Recommendations\n- Increase for high-performance storage systems\n- Decrease if experiencing I/O bottlenecks or storage contention"`
	GetMissingTransactions                int           `key:"blockvalidation_getMissingTransactions" desc:"Concurrency for fetching missing transactions" default:"32" category:"Block" usage:"Parallel transaction fetches" type:"int" longdesc:"### Purpose\nControls parallel fetching of transactions that are not in the local cache but are needed for block validation.\n\n### How It Works\n- During validation, identifies transactions not in local cache\n- Workers fetch missing transactions from DataHub/Asset Server in parallel\n- Fetched transactions are used to complete validation\n\n### Values\n- **32** (default) - Aggressive prefetching for fast validation\n- **Higher values** - Even faster fetching, more network load\n- **Lower values** - Reduced network usage, slower validation\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster validation of blocks with many uncached transactions | More pressure on Asset Server |\n| Lower | Less pressure on Asset Server | Slower fetch times |\n\n### Recommendations\n- Coordinate with Asset Server capacity when adjusting\n- Monitor Asset Server load when increasing this value\n- Reduce if Asset Server is becoming a bottleneck"`
	QuorumTimeout                         time.Duration `key:"block_quorum_timeout" desc:"Timeout for block quorum" default:"10s" category:"Block" usage:"Maximum wait for subtree completion" type:"duration" longdesc:"### Purpose\nProvides a bounded completion time for distributed subtree validation, preventing indefinite waits.\n\n### How It Works\n- Subtree validation is distributed across multiple workers/nodes\n- The quorum timeout defines how long to wait for all subtrees to complete\n- If timeout is reached, block validation is considered failed\n\n### Values\n- **10s** (default) - Reasonable timeout for typical network conditions\n- **Higher values** - More tolerance for slow DataHub or high latency\n- **Lower values** - Faster failure detection, less tolerance for delays\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Longer | Tolerates network issues | Slower failure detection |\n| Shorter | Quick failure detection | May reject valid blocks under load |\n\n### Recommendations\n- Increase if subtree validation is consistently timing out\n- Investigate DataHub performance before increasing significantly\n- Monitor validation failure rates when adjusting"`
	ProcessTxMetaUsingStoreBatchSize      int           `key:"blockvalidation_processTxMetaUsingStore_BatchSize" desc:"Batch size for processing tx metadata from store" default:"1024" category:"Block" usage:"Records per batch" type:"int" longdesc:"### Purpose\nControls the batch size for fetching transaction metadata from the persistent store (not the in-memory cache).\n\n### How It Works\n- When metadata is not in cache, it is fetched from the persistent store\n- Records are fetched in batches to balance efficiency and memory usage\n- Larger batches mean fewer database round-trips\n\n### Values\n- **1024** (default) - Balanced for typical deployments\n- **Higher values** - Fewer database operations, more memory per batch\n- **Lower values** - Less memory usage, more database round-trips\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Larger batches | Better database efficiency | Higher memory usage |\n| Smaller batches | Lower memory footprint | More database overhead |\n\n### Recommendations\n- Increase for systems with ample memory and slow database connections\n- Decrease for memory-constrained environments"`
	UTXOPersisterBufferSize               string        `key:"utxoPersister_buffer_size" desc:"Buffer size for UTXO persister" default:"4KB" category:"Block" usage:"I/O buffer size" type:"string" longdesc:"### Purpose\nControls the I/O buffer size when writing UTXO data to persistent storage during block validation.\n\n### How It Works\n- UTXO persistence writes spent and created UTXOs during block validation\n- Data is buffered before being written to disk\n- Larger buffers reduce the number of system calls\n\n### Format\nSize string with unit:\n- **4KB** (default) - Reasonable balance for most systems\n- **64KB** - Good for high-throughput systems\n- **1MB** - Maximum efficiency, high memory usage\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Larger buffers | Fewer system calls | More memory usage |\n| Smaller buffers | Less memory | More system call overhead |\n\n### Recommendations\n- Increase for high-volume block validation workloads\n- Keep default for typical deployments"`
	UTXOPersisterDirect                   bool          `key:"direct" desc:"Use direct I/O for UTXO persistence" default:"true" category:"Block" usage:"Bypass OS cache" type:"bool" longdesc:"### Purpose\nControls whether UTXO file operations use direct I/O (O_DIRECT flag) to bypass the OS page cache. Prevents cache pollution during high-volume UTXO writes, ensuring cache is available for more important data.\n\n### How It Works\n- **Enabled** - Uses O_DIRECT flag, data goes directly to disk\n- **Disabled** - Uses standard buffered I/O through OS page cache\n- Direct I/O requires properly aligned buffers\n\n### Values\n- **true** (default) - Bypass OS cache (production mode)\n- **false** - Use OS page cache (debugging or compatibility mode)\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Enabled | No cache pollution, predictable performance | Requires aligned buffers |\n| Disabled | May improve small I/O performance | Uses OS caching, cache pollution |\n\n### Recommendations\n- **Production** - Keep enabled to avoid cache pollution\n- **Disable** if the filesystem does not support direct I/O\n- **Disable** for debugging I/O issues"`
	TxStore                               *url.URL      `key:"txstore" desc:"URL for transaction storage" default:"" category:"Block" usage:"Where transactions are stored" type:"url" longdesc:"### Purpose\nAllows transaction data to be stored separately from block data, enabling different storage tiers or backends.\n\n### How It Works\n- When set, transactions are stored at this location instead of within BlockStore\n- Supports the same backends as BlockStore (file://, s3://)\n- Empty string uses the default location within BlockStore\n\n### Format\n- **Empty string** (default) - Use unified storage within BlockStore\n- **file://** - Local filesystem for transaction storage\n- **s3://** - Cloud storage for distributed deployments\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Separate storage | Enables tiered storage | More complex configuration |\n| Unified storage | Simpler setup | Transactions and blocks co-located |\n\n### Recommendations\n- **Most deployments** - Leave empty for unified storage\n- **Advanced** - Configure separately for different performance characteristics or storage costs"`
	UtxoStore                             *url.URL      `key:"txmeta_store" desc:"URL for transaction metadata/UTXO storage" default:"" category:"Block" usage:"UTXO and tx metadata location" type:"url" longdesc:"### Purpose\nDefines the storage location for UTXO and transaction metadata, which requires low-latency access for validation operations.\n\n### How It Works\n- UTXO queries are frequent and latency-sensitive\n- Stored separately from block storage for performance optimization\n- Backend choice significantly affects validation performance\n\n### Format\n- **Empty string** (default) - Uses default Aerospike configuration\n- **Aerospike** - High-performance key-value store (recommended for production)\n- **PostgreSQL** - Relational database option\n- **File-based** - Local storage for development\n\n### Trade-offs\n| Backend | Latency | Scalability | Complexity |\n|---------|---------|-------------|------------|\n| Aerospike | Very low | High | Medium |\n| PostgreSQL | Medium | Medium | Low |\n| File-based | Variable | Low | Low |\n\n### Recommendations\n- **Production** - Use Aerospike for best performance\n- **Development** - File-based or PostgreSQL for simplicity"`
	FileStoreReadConcurrency              int           `key:"filestore_read_concurrency" desc:"Concurrent file reads" default:"768" category:"Block" usage:"Parallel file read operations" type:"int" longdesc:"### Purpose\nControls the parallelism of file read operations, affecting throughput when serving block data.\n\n### How It Works\n- Limits the number of simultaneous file read operations\n- Each read consumes a file descriptor\n- Higher concurrency enables faster block serving to multiple clients\n\n### Values\n- **768** (default) - High throughput for typical systems\n- **Higher values** - More parallelism, may exceed file descriptor limits\n- **Lower values** - Stable operation with limited resources\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Better throughput | More file descriptors used |\n| Lower | Fewer resources | Potential bottleneck under load |\n\n### Recommendations\n- Coordinate with system ulimit settings (check with **ulimit -n**)\n- Reduce if experiencing file descriptor exhaustion errors\n- Consider FileStoreUseSystemLimits for automatic adjustment"`
	FileStoreWriteConcurrency             int           `key:"filestore_write_concurrency" desc:"Concurrent file writes" default:"256" category:"Block" usage:"Parallel file write operations" type:"int" longdesc:"### Purpose\nControls the parallelism of file write operations when persisting block data.\n\n### How It Works\n- Limits the number of simultaneous file write operations\n- Writes are less frequent but more resource-intensive than reads\n- Default is lower than read concurrency to balance resource usage\n\n### Values\n- **256** (default) - Good write throughput for typical storage\n- **Higher values** - More parallelism for fast storage systems\n- **Lower values** - Reduced I/O pressure on storage subsystem\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Higher | Faster block persistence | More storage load |\n| Lower | Less storage pressure | Slower persistence |\n\n### Recommendations\n- Coordinate with storage subsystem capabilities\n- NVMe/SSD arrays can handle higher concurrency\n- Spinning disks benefit from lower concurrency"`
	FileStoreUseSystemLimits              bool          `key:"filestore_use_system_limits" desc:"Auto-detect system limits for file operations" default:"true" category:"Block" usage:"Automatic resource management" type:"bool" longdesc:"### Purpose\nProvides automatic resource management by detecting and respecting system limits like ulimit and file descriptor counts.\n\n### How It Works\n- **Enabled** - Queries system limits and adjusts concurrency accordingly\n- **Disabled** - Uses explicit concurrency values regardless of system limits\n- Prevents errors from exceeding file descriptor limits\n\n### Values\n- **true** (default) - Automatic limit detection (safe mode)\n- **false** - Use explicit values (manual mode)\n\n### Trade-offs\n| Setting | Benefit | Drawback |\n|---------|---------|----------|\n| Enabled | Safe operation | May reduce configured concurrency |\n| Disabled | Full control | Risk of errors if limits exceeded |\n\n### Recommendations\n- **Keep enabled** for safe operation in most environments\n- **Disable** only when you need exact control over concurrency and have verified system limits are sufficient"`
}
